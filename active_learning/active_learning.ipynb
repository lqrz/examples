{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Active learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    ">\"Active learning [1] is the subfield of machine learning that makes\n",
    "algorithms active participants in data annotation with the objective to learn the target\n",
    "function more economically (Settles 2012). By carefully choosing which instances\n",
    "should be annotated, active learning algorithms can reduce the time, effort, and\n",
    "resources needed to train an accurate predictive model.\" [2]\n",
    "\n",
    "## Common techniques\n",
    "\n",
    "A recap of some active learning techniques:\n",
    "1. _Bias towards uncertanty_: certain models directly output the prediction uncertainty. I should gather those which I'm least certain about.\n",
    "2. _Bias towards ensemble disagreement_: when using ensemble methods, I should focus on those samples that present the highest disagrement.\n",
    "3. _Bias towards labels most likely to influence my classifier_: if I have a similarity measure between samples, I could pick those that are more disimilar (i.e. they have features that I haven't seen before).\n",
    "\n",
    "If I apply the previous strategies, it is likely that I'm gonna end up having outliers (very strange samples). I should be aware of that and try to _bias towards denser regions of training data_.\n",
    "\n",
    "_Random sampling_ is the most common baseline that is used for comparing against\n",
    "active learning strategies [2].\n",
    "\n",
    "Authors in [3] analysed the most common active learning strategies (at the time '09):\n",
    "![Active learning strategies](guyon.png)\n",
    "They mostly use \"Uncertainty sampling\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "\n",
    "[1] \"Improving Generalization with Active Learning\", Cohn [URL](http://www.cs.northwestern.edu/~pardo/courses/mmml/papers/active_learning/improving_generalization_with_active_learning_ML94.pdf)\n",
    "\n",
    "[2] \"Active learning: an empirical study of common baselines\", Ramirez-Loaiza [URL](http://download.springer.com/static/pdf/467/art%253A10.1007%252Fs10618-016-0469-7.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10618-016-0469-7&token2=exp=1488298177~acl=%2Fstatic%2Fpdf%2F467%2Fart%25253A10.1007%25252Fs10618-016-0469-7.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1007%252Fs10618-016-0469-7*~hmac=216172ab0739fe368f70e7a5237ffae1cbfa3b2d5571223db8abb227fd19b759)\n",
    "\n",
    "[3] \"Results of the Active Learning Challenge\", Guyon [URL](http://www.jmlr.org/proceedings/papers/v16/guyon11a/guyon11a.pdf)\n",
    "\n",
    "[3] \"Real world active learning - Machine learning\" [YouTube](https://youtu.be/NQrkfLbX4tQ)\n",
    "\n",
    "[4] \"Applying active learning to supervised word sense disambiguation in MEDLINE\", Chen [URL](https://academic.oup.com/jamia/article/20/5/1001/726173/Applying-active-learning-to-supervised-word-sense)\n",
    "\n",
    "[5] Curious snake: a Python Active learning framework [GitHub](https://github.com/bwallace/curious_snake)\n",
    "\n",
    "[6] http://active-learning.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
