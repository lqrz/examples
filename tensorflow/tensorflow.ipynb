{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 8]\n",
      "b'Hello, TensorFlow!'\n",
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.Variable(x+5) # defining ```y=x+5``` is the same.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "# we use the `with` statement so that the session closes automatically at the end of the with block.\n",
    "# we need to close the session in order to release assigned resources.\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #i can do ```session.run()``` or ```variable.eval()```\n",
    "    print(session.run(y))\n",
    "    print(hello.eval())\n",
    "    print(session.run(hello))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### I can update tensorflow variables in loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(initial_value=0, dtype=tf.int64)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for i in range(3):\n",
    "        x += 1\n",
    "        print(session.run(x))\n",
    "        print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Linear equation solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation: y = 3.0x + -1.0\n"
     ]
    }
   ],
   "source": [
    "#point 1\n",
    "x1 = tf.constant(value=1., dtype=tf.float32)\n",
    "y1 = tf.constant(value=2., dtype=tf.float32)\n",
    "\n",
    "#point 2\n",
    "x2 = tf.constant(value=0., dtype=tf.float32)\n",
    "y2 = tf.constant(value=-1., dtype=tf.float32)\n",
    "\n",
    "#im using tf.pack to create the tensor\n",
    "points = tf.transpose(tf.pack([[x1,y1], [x2,y2]]))\n",
    "ones = tf.ones((1,2))\n",
    "params = tf.matmul(ones, tf.matrix_inverse(points))\n",
    "\n",
    "with tf.Session() as session:\n",
    "#     print(points.eval())\n",
    "#     print(ones.eval())\n",
    "    result = session.run(params)\n",
    "    a = result[0][0]\n",
    "    b = result[0][1]\n",
    "    print(\"Equation: y = {a}x + {b}\".format(a=a, b=b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Saving and restoring variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow does not save the model, only (the specified) variables. This means that when we restore the model, the computational graph must be the same as when we performed the save operation.\n",
    "\n",
    "Some people make a unique workflow where they include the graph creation, the saving and restoring of the params and then put a flag to distinguish between training and prediction.\n",
    "\n",
    "I can otherwise use the `tf.get_variables()` method for initializing/retrieving variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### A function approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSpQSgIhIifo/A2LFP6oTe3oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86bd29c6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.linspace(-1*np.pi, 1*np.pi, 100)\n",
    "y_sin = np.sin(x_train)\n",
    "y_train = np.random.normal(y_sin, scale=0.2)\n",
    "\n",
    "plt.plot(x_train,y_train)\n",
    "plt.plot(x_train,y_sin)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of minibatches: 13\n",
      "23.4483643174 56.1083\n",
      "1.42278054357 44.9501\n",
      "1.39841681719 45.4752\n",
      "1.39023565501 45.4231\n",
      "1.3853322342 45.348\n",
      "1.38188690692 45.2836\n",
      "1.37926689535 45.23\n",
      "1.37717663497 45.1847\n",
      "1.37545398623 45.1458\n",
      "1.3739997074 45.1118\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86bcef8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "minibatch_size = 8\n",
    "\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(1234) # seeds are applied at graph level.\n",
    "    x = tf.placeholder(dtype=tf.float32, name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, name='y')\n",
    "    \n",
    "    n_hidden = tf.constant(value=10)\n",
    "\n",
    "    w1 = tf.Variable(initial_value=tf.random_normal(shape=[1,n_hidden], stddev=.2), name='w1')\n",
    "    b1 = tf.Variable(initial_value=tf.random_normal(shape=[n_hidden], stddev=.2), name='b1')\n",
    "    w2 = tf.Variable(initial_value=tf.random_normal(shape=[n_hidden, 1], stddev=.2), name='w2')\n",
    "    \n",
    "    hidden_activations1 = tf.tanh(tf.matmul(x,w1)+b1)\n",
    "    forward_pass = tf.matmul(hidden_activations1, w2)\n",
    "\n",
    "    l2 = tf.reduce_sum(tf.add(tf.square(w1), tf.square(w2)))\n",
    "    mse = tf.square(tf.sub(y, forward_pass))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.add(mse, 0.001*l2))\n",
    "\n",
    "    train_op = tf.train.AdagradOptimizer(0.8).minimize(loss)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    n_minibatch = np.int(np.ceil(x_train.shape[0]/np.float(minibatch_size)))\n",
    "    print('Nr of minibatches: %d' % n_minibatch)\n",
    "    \n",
    "    for epoch_ix in range(3000):\n",
    "        epoch_loss = 0\n",
    "        for minibatch_ix in range(n_minibatch):\n",
    "            _, output_loss = session.run([train_op, loss], feed_dict={x: np.matrix(x_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]).T, y: y_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]})\n",
    "            epoch_loss += output_loss\n",
    "        \n",
    "        if (epoch_ix%300) == 0:\n",
    "            print(epoch_loss, l2.eval())\n",
    "    \n",
    "    predictions = session.run(forward_pass, feed_dict={x:np.matrix(x_train).T})\n",
    "\n",
    "    plt.plot(x_train, y_train, color='blue')\n",
    "    plt.plot(x_train, y_sin, color='green')\n",
    "    plt.plot(x_train, np.array(predictions).reshape((-1,)), color='red')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### About minibatch sizes:\n",
    "From: https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent\n",
    "\n",
    "The two main things to consider when optimizing mini-batch size are the time efficiency of training and the noisiness of the gradient estimate. \n",
    "\n",
    "Let's say we have a dataset with 100,000 training examples, and we are considering a mini-batch size of 100 and 10,000. Computing the gradient of a batch generally involves computing some function over each training example in the batch and summing over the functions. In particular, gradient computation is roughly linear in the batch size. So it's going to take about 100x longer to compute the gradient of a 10,000-batch than a 100-batch. \n",
    "\n",
    "This means that the 100-batch version of our model is going to make 100 parameter updates in the time it takes the 10,000-batch model to make 1 update. The gradient of the 100-batch isn't going to be quite as accurate as the gradient of a 10,000-batch, so the 100 updates probably won't be 100x as productive as the single update from the larger 10,000-batch. But they might be 10x more productive, which drastically cuts down on total training time.\n",
    "\n",
    "On to the noisiness part of the equation. When we compute the gradient of a mini-batch, what we're really doing is approximating the gradient of the entire training set. Obviously, the gradient of a single data point is going to be a lot noisier than the gradient of a 100-batch. This means that we won't necessarily be moving down the error function in the direction of steepest descent. \n",
    "\n",
    "But noisiness isn't all bad. In particular, suppose that our error function is particularly pernicious and has a bunch of little valleys. If we used the entire training set to compute each gradient, our model would get stuck in the first valley it fell into (since it would register a gradient of 0 at this point). If we use smaller mini-batches, on the other hand, we'll get more noise in our estimate of the gradient. This noise might be enough to push us out of some of the shallow valleys in the error function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Visualizing the graph\n",
    "Im gonna add `tf.name_scope()` statements to the previous graph definition so that the visualization is more friendly. And Im gonna make use of some functions for inline plotting (taken from: http://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.5068384497078885&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/shape/0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;random_normal/shape/0&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 1234\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 7\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal/RandomStandardNormal&quot;\\n  input: &quot;random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal/mul&quot;\\n  input: &quot;random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;w1&quot;\\n  input: &quot;random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;w1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;random_normal_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 1234\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 16\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal_1/RandomStandardNormal&quot;\\n  input: &quot;random_normal_1/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal_1/mul&quot;\\n  input: &quot;random_normal_1/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;random_normal_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/shape/1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Const&quot;\\n  input: &quot;random_normal_2/shape/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;random_normal_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 1234\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 26\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal_2/RandomStandardNormal&quot;\\n  input: &quot;random_normal_2/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal_2/mul&quot;\\n  input: &quot;random_normal_2/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w2&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w2/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;w2&quot;\\n  input: &quot;random_normal_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;w2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;w2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Forward_pass/Layer_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;w1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Forward_pass/Layer_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Forward_pass/Layer_1/MatMul&quot;\\n  input: &quot;b1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Forward_pass/Layer_1/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Forward_pass/Layer_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Forward_pass/Layer_2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Forward_pass/Layer_1/Tanh&quot;\\n  input: &quot;w2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/L2/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;w1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/L2/Square_1&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;w2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/L2/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Loss_function/L2/Square&quot;\\n  input: &quot;Loss_function/L2/Square_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/L2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/L2/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/L2/Add&quot;\\n  input: &quot;Loss_function/L2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/MSE/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;y&quot;\\n  input: &quot;Forward_pass/Layer_2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/MSE/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;Loss_function/MSE/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Loss/mul/x&quot;\\n  input: &quot;Loss_function/L2/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Loss_function/MSE/Square&quot;\\n  input: &quot;Loss_function/Loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;Loss_function/Loss/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;Loss_function/Loss/range/start&quot;\\n  input: &quot;Loss_function/Loss/Rank&quot;\\n  input: &quot;Loss_function/Loss/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Loss_function/Loss/Add&quot;\\n  input: &quot;Loss_function/Loss/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/Loss/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/Loss/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Loss_function/Loss/range&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/mod&quot;\\n  op: &quot;Mod&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/add&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range/start&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Size&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/range&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/mod&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/DynamicStitch&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/floordiv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Fill&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/Loss/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/Loss/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_2&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Shape_3&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Prod_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/floordiv_1&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Prod&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Maximum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/floordiv_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/truediv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Tile&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Loss_function/MSE/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/truediv&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Mean_grad/truediv&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Sum_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul/x&quot;\\n  input: &quot;Loss_function/MSE/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Loss_function/L2/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Loss/mul/x&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/Add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/mul_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Sum_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Forward_pass/Layer_2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Square_grad/mul_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Neg&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/Loss/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;w2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Forward_pass/Layer_1/Tanh&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/MSE/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Tile&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Sum_grad/Tile&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Sum_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;Forward_pass/Layer_1/Tanh&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul/x&quot;\\n  input: &quot;w1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul/x&quot;\\n  input: &quot;w2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Forward_pass/Layer_1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/Tanh_grad/TanhGrad&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/Tanh_grad/TanhGrad&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Sum_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_1_grad/mul_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;w1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul_1&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Loss_function/Optimizer/gradients/Loss_function/L2/Square_grad/mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w1/Adagrad&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w1/Adagrad/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Loss_function/Optimizer/w1/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w1/Adagrad/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/w1/Adagrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/b1/Adagrad&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/b1/Adagrad/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Loss_function/Optimizer/b1/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/b1/Adagrad/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/b1/Adagrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w2/Adagrad&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w2/Adagrad/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Loss_function/Optimizer/w2/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/w2/Adagrad/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Loss_function/Optimizer/w2/Adagrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Adagrad/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.800000011920929\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Adagrad/update_w1/ApplyAdagrad&quot;\\n  op: &quot;ApplyAdagrad&quot;\\n  input: &quot;w1&quot;\\n  input: &quot;Loss_function/Optimizer/w1/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Adagrad/learning_rate&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Adagrad/update_b1/ApplyAdagrad&quot;\\n  op: &quot;ApplyAdagrad&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;Loss_function/Optimizer/b1/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Adagrad/learning_rate&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/Forward_pass/Layer_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Adagrad/update_w2/ApplyAdagrad&quot;\\n  op: &quot;ApplyAdagrad&quot;\\n  input: &quot;w2&quot;\\n  input: &quot;Loss_function/Optimizer/w2/Adagrad&quot;\\n  input: &quot;Loss_function/Optimizer/Adagrad/learning_rate&quot;\\n  input: &quot;Loss_function/Optimizer/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@w2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Loss_function/Optimizer/Adagrad&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Loss_function/Optimizer/Adagrad/update_w1/ApplyAdagrad&quot;\\n  input: &quot;^Loss_function/Optimizer/Adagrad/update_b1/ApplyAdagrad&quot;\\n  input: &quot;^Loss_function/Optimizer/Adagrad/update_w2/ApplyAdagrad&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.5068384497078885&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "minibatch_size = 8\n",
    "\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(1234) # seeds are applied at graph level.\n",
    "    x = tf.placeholder(dtype=tf.float32, name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, name='y')\n",
    "    \n",
    "    n_hidden = tf.constant(value=10)\n",
    "\n",
    "    w1 = tf.Variable(initial_value=tf.random_normal(shape=[1,n_hidden], stddev=.2), name='w1')\n",
    "    b1 = tf.Variable(initial_value=tf.random_normal(shape=[n_hidden], stddev=.2), name='b1')\n",
    "    w2 = tf.Variable(initial_value=tf.random_normal(shape=[n_hidden, 1], stddev=.2), name='w2')\n",
    "    \n",
    "    with tf.name_scope('Forward_pass') as scope:\n",
    "    \n",
    "        with tf.name_scope('Layer_1') as scope:\n",
    "            hidden_activations1 = tf.tanh(tf.matmul(x,w1)+b1)\n",
    "            \n",
    "        with tf.name_scope('Layer_2') as scope:\n",
    "            forward_pass = tf.matmul(hidden_activations1, w2)\n",
    "        \n",
    "    with tf.name_scope('Loss_function') as scope:\n",
    "        \n",
    "        with tf.name_scope('L2') as scope:\n",
    "            l2 = tf.reduce_sum(tf.add(tf.square(w1), tf.square(w2)))\n",
    "            \n",
    "        with tf.name_scope('MSE') as scope:\n",
    "            mse = tf.square(tf.sub(y, forward_pass))\n",
    "\n",
    "        with tf.name_scope('Loss') as scope:\n",
    "            loss = tf.reduce_mean(tf.add(mse, 0.001*l2))\n",
    "\n",
    "        with tf.name_scope('Optimizer') as scope:\n",
    "            train_op = tf.train.AdagradOptimizer(0.8).minimize(loss)\n",
    "\n",
    "with graph.as_default():\n",
    "    show_graph(graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Modularizing the code\n",
    "This means, making sure that all tensors and ops belong to the same graph (ie, making sure that we always use the same graph), and sharing tensors across different pieces of code via `tf.variable_scope()` and `tf.get_variable()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of minibatches: 13\n",
      "28.7143582031 47.896\n",
      "1.45079540461 46.9396\n",
      "1.41267189384 47.0129\n",
      "1.3997015208 47.0901\n",
      "1.39240346104 47.0244\n",
      "1.38759235293 46.9553\n",
      "1.38415535539 46.8981\n",
      "1.38153445721 46.8509\n",
      "1.37943602353 46.8107\n",
      "1.37769798189 46.7755\n",
      "[[  8.03185821e-01  -8.17269090e-14   7.99236357e-01  -1.75505166e-11\n",
      "    8.03261578e-01  -1.17340901e-10   7.12581171e-14   8.58609974e-01\n",
      "   -3.53853255e-16  -2.98837777e-02]]\n",
      "[  3.76370288e-02  -1.22946466e-12   2.13520336e+00  -2.84377244e-10\n",
      "   3.76262106e-02  -1.80569393e-09   1.51161375e-12  -2.10519099e+00\n",
      "  -8.38311981e-15  -2.07570493e-01]\n",
      "[[  6.71226442e-01]\n",
      " [  1.03831664e-13]\n",
      " [ -7.32662022e-01]\n",
      " [  2.29544508e-11]\n",
      " [  6.71453059e-01]\n",
      " [  1.49052715e-10]\n",
      " [ -9.86810053e-14]\n",
      " [ -7.53405988e-01]\n",
      " [  5.17217588e-16]\n",
      " [  3.73049341e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdYFUcXh9+lgyIqgqKABSvGjmLvvdeosWFv0USjRj8T\n00wxxRJrLLHElqiJvURjTVQUCzZAEAsoWFAUsSAw3x/D0kEQBIV5n+c+y907uzsXcX97zpyiCSFQ\nKBQKRe7DILsnoFAoFIrsQQmAQqFQ5FKUACgUCkUuRQmAQqFQ5FKUACgUCkUuRQmAQqFQ5FKUACgU\nCkUuRQmAQqFQ5FKUACgUCkUuxSi7J5AahQoVEiVKlMjuaSgUCsVbw6lTp+4JIWzSMvaNFoASJUrg\n4eGR3dNQKBSKtwZN066ndaxyASkUCkUuRQmAQqFQ5FKUACgUCkUuRQmAQqFQ5FKUACgUCkUuRQmA\nQqFQ5FKUACgUCkUuRQmAQqHIMD4+sHt3ds9CkV7e6EQwhULxdjBmDJw9C3fuZPdMFOlBCYBCocgQ\nISGwfz9ERcGLF2BsnN0zUqQV5QJSKBQZYutWefMHuHs3e+eiSB9KABQKRYbYtCnuZ+UCertQAqBQ\nKF6Zhw/h77+hdm35/vbt7J2PIn0oAVAoFK/M9u3S7z96tHyvBODtQgmAQqF4ZTZuhGLFoGNH+V65\ngN4ulAAoFIpX4vFjGfvftStYWoK5ubIA3jaUACgUildi50549gy6dwdNA1tbJQBvG0oAFApFuhEC\nfvkFCheGevXkvsKFlQC8bahEMIVCkW6WLZPJX/PmgaGh3Fe4MAQEZO+8FOlDWQAKhSJd3LgB48dD\n48YwcmTcfuUCevtQAqBQKNKMEDBkCERHw6+/gkG8O0jhwjIKKDo6fef77Tdo2BACAzN/vorUUQKg\nUCjSzLJlsHcvfP89lCyZ8LPChWVJiAcP0nYuf39o1Qr694cjR+DgwUyfruIlKAFQKBRpZtEicHGB\nESOSfmZrK7dpcQN5ecE778Dx4zB7towi8vfP3LkqXo4SAIVCkSaEAG9vqFs3oetHp3BhuU2LAOzb\nB0+fwokT8MEHMplMCUDWowRAoVCkiZs3ITwcypdP/vP0CICXF+TPD+XKyfelSikByA6UACgUijTh\n7S23LxOAtJSDuHQJKlSQrh9QApBdKAFQKBRpwsdHbvWn9sQUKCBzAtJqATg7x70vVUpaGM+eZXye\nirSjBEChUKQJb29Z88fOLvnPDQzSlgsQEiKthAoV4vaVKiW3V69mzlwVaUMJgEKhSBPe3tL9o7tt\nkkPPBUgNLy+5TWwBgHIDZTWZIgCapv2qadodTdMupPC5pmnaz5qm+Wmadk7TtOqZcV2FQpF16AKQ\nGmmxAC5dktvkLAAlAFlLZlkAK4DWqXzeBigT8xoGLMyk6yoUigywbl3aFm0fP5aZuin5/3XSUhDO\nywssLMDRMW6fra3c9yoCcPEi3LqV/uMUmVQMTghxWNO0EqkM6QSsEkII4Limafk1TbMTQgRlxvUV\nCkX6uX8f3nsPPv0Uvvwy9bGXL8vtyywAXQDCnj/mwbP73H96n8cRjzE2MMbE0AQLYwvOeRejfPm8\nCXIJNO3VIoGCgmQ7yg4dYO3a9B2ryLpqoMWA+HUCA2P2JREATdOGIa0EHOM/IigUikwlOFhuLyTr\nuE1IaiGgNx7eYP/V/Zy4eYI9+S7xbMwl8n13N+WT1QaTqILUWFyCGnY1cC3miqu9K6WcKuJ/JZUF\nhmSYPFlaJ2n5DoqkvHHloIUQi4HFAC4uLiKbp6NQ5AgCA8HePuE+3VWTlpunj4+M8ildGoQQnLh5\ngrXn17LDdwdXHlwBwMrUChvjiuDdiQmDS1PeoRAFzQuS1yQvkdGRRERFcOdhGMMmBFK15Q2szP3Y\neGkjS04vASBvFXue0YFdvh1pXqoZxobGqc7J3R1WrZKRSb6+sghdchnKipTJKgG4CTjEe28fs0+h\nULxmvLygYkU4cAAaNYrbrwvAlSuyLIO5ecrn8PYGhwp3mHF8ESs9V+L/wB9TQ1NaOLVgTK0xNC3Z\nlIq2Fdn7twGtp0Dnj6FeMqEeJ08C/8KUj6BzZykmfvf9OHLjCHN2b+dcxZW0XbuQInmLMKjqIIZU\nH0LJAiWTnCc6GsaOlSGpEybARx/JXgTFi8eN2btXFqZ7991X+73lBrJKL7cC/WOigWoDD5X/X6HI\nGjw94+r4xEcXgOjopJ/Fx+uuF3sthhDQzZHPDn5GyfwlWd5pObcn3GZb7218UPsDKhWuhIFmEFsQ\nLqWF5cQRQJqmUca6DIOqDeLbKn/C9yF8V3UzLkVd+O6/7yj1cym6/t6VM0FnEpznt99kHaHvvoMa\nNeQ+PVFNZ+pUucZx+vRLfkG5mMwKA10HHAPKaZoWqGnaYE3TRmiaptcM3An4A37AEmBUZlxXoVC8\nHD8/uQ1K9MgV/yadnBvoeuh13Da7UXFBRR4UW8s7kW5cGnWJff334VbVDSszqyTHvKwekJcXGBuD\nk1PSz0qVAiLNsH/ciW29t3H9w+tMbTCV/Vf3U31xddqvbc/Z4LMIAZ98Aq6u0LdvXGRSfAGIjITz\n52V5ajc3iIiI+0yIhO9zM5kiAEKI3kIIOyGEsRDCXgixTAixSAixKOZzIYQYLYRwEkJUEkJ4ZMZ1\nFQrFy0lJAG7fBhsbMDFJKACPnj+i1/KPKDu3LOsvrGdIxY9g1g3eL7GICjYVSA0bm7hzJ8elS1C2\nLBgl43wuUUJu9Ugg+3z2TG86nesfXmd6k+kcCzxG9V+q8+5vwwh8cIdhw6TPv3BhyJcvoQBcvizL\nSvTqJYXgq6/kfi8vqFkTqlRJ9WvkGt64RWCFQpG5+PrKbeJY+du3ZRlmOzspAEIINnlt4oNdH3Ar\nLIg8lwdxZPpn3L7swJIniSKAwsNl3YbgYHj0CMLCICICYxMThuQ1xcY9L5wuKi9gYxO7OuvlBdWq\nJT9PMzM5/MqVhPutzKyY2nAqo2uN5stDXzLn+FwY8zvXC08nWozGQDOgXLmEAuDpKbdTpoCpKXz7\nrXzq//nnuHpD4eGQJ8+r/U5zCkoAFIq3AHd36fMeMyb9x6ZmARQuDNbWcOh0EB3WDWWH7w6c8lSF\npX8SftOVsQHQs/FtOnOUGhvc4bMT8jE+lWyvJQC7Yl4g7+wVKxLpXJm2V6pSvmlDiK6cbMhOarkA\n+c3yM7PVTLxWD+eA6Qd86TGWA3c2sKzjMsqWLcPhw3Fjz56Vlk358rLhjN7FrG1baNIEJk5MW2Jb\nTkeTuVlvJi4uLsLDQ3mLFIpBg2TI4+PH8n6aVh49AqsYV33RorLipk6JErIXb3S5v1jzaChmluF8\n3exrAjeN5eAcL5a030zU5m3U4iQAwtgYrUoV6T9xcpJ3azs7eQFLS3nHjYigf68IzCIesfjzW/KC\n/v5w/jwvTp/DOCRGOKytZVf5zp1lFlfMJN3cZLOYlPoDCyEv2ay5oMWElYzbM45nkc9oGvU9Oz97\nn8ePNfLkka0m796NWwD29JSWULducOiQFIF9+6BZs7T/Lt8WNE07JYRwSctYZQEoFG8BQUFyQdPH\nJ33+a/3pv3x5eQOMipIlm4WA4JAnnHUcy/nIZRBanTWu8+jq4cGl+bWYGXkGtmgEFK3FJ7e+4s47\nzVh8slqa1CeiFBw/DXROuP+PNTC5bwD/TT+Io99++Ptv2LRJrgq3aAFubpR27MTKmyY8e5b8pXx8\npPHRpLGGW1U3Wjq1ZNi2YezwHQs993Pq4q80rFWAs2ehXbu443TdAnCICUgPCEh6/tyGEgCF4i1A\nz9q9ePHVBKBhQxnqee+edPucC/Dned+uXDA+x6eFRlD4C0HH5U3hxTOeUp1/Os+l2aIeFLMpTOhY\ncKkMpNHysLWV802cmLVtGzy3caDox/3AqJ8ccOIEbNwIf/wB777LBEsbTHAj8L/RlG5WPMm5Dx2S\nWz2foahlUbb13sbEP2fzU9Qkuu2txkrT37lzx5WqVZOfX7FicqsEALnw86a+atSoIRQKhRCFCwsB\nQkyZkr7jvv5aHrdqldyeOSPELt9dwuqbAqLMUEtx2qWhiDYwEM8wEUcrDhEbPz0rQIgLF159rr/9\nJq918GDcvidPhMiTR4jhw1M4KDJSiJ07xb2GXcQLDEWUgaEQffoI4emZYFivXkIULSpEdHTCw8PD\nhaCYu8j/eQlh9IWJoMrKBNdPjI2NEMOGvdr3e9MBPEQa77EqcVqheMOJjIyL2U9vzRtfX+n7L10a\nQLDwzGwG/NKGudsNuLjkKZUunEKbMIEuVa7yaZElrL1YBXv7hLX600vXrnJJYPnyuH27dsmomx49\nUjjI0BDatMF425+UMbzKfzU+gC1bpLnTpQtcuIAQ0gJo1ChpTwILC3A0rEUzPw8cqQddBrApbBJR\n0VHJXs7BQVkAoBrCKBRvPHfuSJ+9pkkXUHrw85M3f5vCkRi0fh+TDeO4Ot+IPsdDWcJQvLdfgRkz\nKFK9KOfOyYXRNm1Sb/ryMiwsoGdP6dl5/Fju27gRChVKWIoiOfLlg+L1HRj74ie4cQO++AL274fK\nlQnr0h/joOspnqNcObjubU2NS3uw9BrF3FM/0Pn3zjx58STJWCUAEiUACsUbju7/r1ZNBtSEh6f9\nWD8/KF4mnFnrm3H0/ALm7gLz+o35/ZMLjGYB1s4ydfedd2TUzKNH0Dq1zh5pxM1NznPDBllnaNs2\naRkklwCWmDZtZBhn0LMCMG2a/NITJmCxcwPelKfbuc/gSdKbup4LcO6sMc2ez2dem3ns9N1Js1XN\nCHkSkmCsvX3KkUa5CSUACsUbhJdXXBKTjh6/37y53Or1dF5GWBjceRBCpavOzP70MCXv5GVF89Vo\ne/7GR5NZXXrm7jvvyK2RUeaERtatC2XKwIoVsGePtARSdP8kQhegPXtidlhbw/ffM77dZXabdqbQ\ngi9lWNOffyY4rlw5+Z19fKBqVRhdazQbemzgTNAZ6v1aj+uh12PHOjhAaGichZJbUQKgULxBjBoF\nAwcm3JdYANLqBjr/zykOFCjOxP03CGpZl86lrrPVsg9oGrdvy/uq/kResaLc1q0blzeQETRNWgGH\nD8MPP8SF/aeFypVlrP+uXXH7oqPhz5MO/N55nVwIKFBABvV37Rqb4hw/qUuPlOpaoSt/9/ub4MfB\n1Pu1HpdDZGcbvTR2brcClAAoFG8Q3t7SbRM/P1MXgHr1ZFmDtCwEh6xfTsXetah6P5y9EybguPNf\nLOwLxp7rzp24wm0gF4qbNoWhQzPvu/TvL4Xg6FG5jpsW9w/IY1q3lmkCkZFy34YNMqesUydkTKuH\nhywFumuXLC26ZAnlysb90uKHgDYs3pDDAw8TERVB4xWN8brrpXIBYlACoFC8IYSFSX9/WJhs16gT\nHAwFC8rF1QoVXmIBREcTNnk81r0H4VcAqhZaT53PfgBNw84uTkz0MhA6mgb//COra2YW9vYyvwvS\n7v7RadNGumhOnJA1fKZOhUqV4tX2NzaGjz+Wld6qV4dhw3AY2Z6SZkFYWSXsCwBQuXBlDrodJFpE\n03hlY57klSqqBEChULwR6EXbIGE9nKAgKFJE/vzOO6lYAA8f8qxdKyxnzGJ1dSO+brePp9E9yZtX\nfly0qDyXEEkF4HUxdSp07y5LL6SHFi1kZOiuXbB0qSwQ9+23cl8CSpeWyjVnDtqB/Zx+8Q7jHDYm\nG8XkbOPMIbdDGBkY0W9fE7C5pFxA2T0BhUIhiS8AV6/G/RwUJH3iIAUgMFA+HScgMJAX9epg+Pc+\nxnUwocSf+wm53CQm/l9iZyefph88kAKgN295nTRsKN03xql3d0xC/vyy2fvmzTIStEEDWcgtWQwM\nZHuwM2cwq1CKzy70gOHDk48UKlSOQ26HMDY0xsCtORdu+aX/S+UglAAoFG8IaREAfbFWjwTy9ITv\n+54jytWV51d86DLAlK5z91G/eAN8fWUkjo5+jqtXpZspKyyAjNCmjbR27tyBGTPSkJtQvjxmp/6T\npT4XL4ZatZI1l0oXLM2+/vswMHrBtoLNEkQH5TaUACgUbwi+vrJOTaFCcS4gIeQaQHwXEMj72v37\n8F2rA4xYU597T+7RaJABY6dupUHxBoSHS+FIbAGAjLGHN18A9HDQzp2hTp00HmRiIus+794tExtq\n1ZL9IxPhbONM/Wt/E6E9ovlvzbn9OOXy1jkZJQAKxRuC/sResmScBRAaCs+fx928HR0hb1659jm3\n9Q6W327DDSuBy8AIJo9aS0unlkBcU5W3WQCqV4e5c2HevFc4uFUr+UVr1pThSCNHyl9kPCoVqobZ\npp3cfHSTtmvbEvY8LHMm/hahBECheENITgD0qB395m1gIOv0hPyykSknu+BfNC+Nhj+mRv7F9KgY\nF2rj5SW38WPjEwtAVqwBZARNg/ffj6vemW7s7OQC8cSJsGiRXEiIF/Zjbw9PfOqwst0GPIM96fZH\nNyKiclezYCUACsUbQGioLNVcpozss3L9uqzdr5eB0G/eAIPN1/Lbi55cLFKYOv1DiPb5AgvvhAH8\nZ8/KuPv4bRzz5pVF2vRM4zfdAsgUjIykS+ivv2SShYsLeuswPRegokk7lnRYwl7/vQzcMpBoEZ2N\nE85alAAoFG8A+gJw2bLSAnjxQiY+6RaAvgbAhg0MPdKPU4XL0GBgID3qDKZ2xKdJykN4esqcAVPT\nhPvt7OQCMOQSAdDp3Fn21cyfX9a6mD8fB3uZOBYQAAOrDeSbpt+w9vxaph2YluDQkBDo00e6ovSq\nrDkFJQAKxRuALgC6CwjkQnACF9DWrfDee4RWq0CLwb7Ud27FwnYLqeis4e0tLQYdT0+SbYiiWxL5\n8qWvtWSOoEIFmVnWqhW8/z5VFo3EiBexuQCT609mSLUhfH3ka1acXRF72I4dsHat7MdctKgMR718\nOXu+QmajBECheAO4fFn6vEuVki+Q6wBBQWBuDvmO7YEePXhauQKV2wdQ0qESG3pswNjQGGdnub55\n7Zo87t49WR4nuc5hugC86f7/14aVlewzMHkylmt/4W9acs9HVgrVNI0F7RbQrGQzhm0bxsFrBwEp\npmZmcOaMXE5wd5c1k44ezcbvkUkoAVAo3gB8fWWEj5mZ3BoYSAEIDobWBdzRunUlslxZ6vUI40Ve\nc7b23oqlqSUQ17wlfm4ApC4Aucr9kxhDQ5lW/Ntv1OEYAxfVil01NzY0ZuO7GyldsDRdf++Kb4gv\nnp4y/LZqVXnYiROyNEfTprKl8duMEgCF4g0gftKWsbFcoPT3B6MrPvx6px2isC3vDrbkYuQt/ur5\nF45WjrHHVqggt0oA0knfvoyqcBCj5+Ey0WDvXgDym+Vnx3s7MNAM6LS+E2cuPaJy5bjDnJzk03+N\nGrLG0ZEj2TT/TEAJgEKRzQhBkqzdkiUhzOcW35xqhWZowGeT6/BX6DGWdVxGHYeEWVFWVtI3rYd+\nenrKG71e6z8+RYvKrRIAycMKtXnX0V2aXW3awMKFAJQsUJINPTZwOeQy9xv3oVLlhJFBhQrJMhVC\nwKlT2THzzEEJgEKRzYSEyDDQ+AJQ3v4xX59tR77IECb1GM5XQeuYVHcSfSsnX67T2TmhBZDc0z+o\nNYDE2NuDe3Bxog79KxeHR42C8eMhKoomJZsw3HEOlNvOqXyfJjnW2lq66kJCkjnxW0KmCICmaa01\nTfPRNM1P07TJyXzupmnaXU3Tzsa8hmTGdRWKnED8CCAAoqIYd/I9KkSe413rL1lW+ntaOrXkm2bf\npHiOChWkADx/LrcpCYCyABLSoIHsCvbJ9/lklNXYsTBrlmw2Ex6OQ/AoODWE1Te+YeOljQmONTCQ\nfWnil+5+28iwAGiaZgjMB9oAzkBvTdOckxn6uxCiasxraUavq1DkFOLnAAAwaRJlfbYx1mQ6uwf8\nSAHDYqzrtg5Dg8S1kONwdpY9ePftkzkEKQlAuXLy/hZbVz+X0727LBz63Xew9ndDmDMHfv5ZNjFu\n1Igb7sE4nJ9PbfvaDNwyEK+7XgmOt7ZWFkAtwE8I4S+EiADWA50y4bwKxVtPeLhsZ5gavr4yMKVk\nSeCXX2DmTG52f58FfXaB+QM+r/AXBc0LpnoOPRJo3Tq5TUkANA0+/FDeuBSSn3+WZasHD5aNxhgz\nRoaKenvz6XZXOhX3YUOPDVgYW9D1j64JagYVLKgEoBgQv69OYMy+xHTTNO2cpmkbNU1zyITrKhRv\nNM+fQ4kSsjJxavj6ynHGxw7L4jdt2/JtL1MofgS2LaaeUwp383joArB5s8z+jbUmFC/FxAQ2bpRu\nsc6dYzKl27fn+b4jREdG8cPx+tgfv8Tv3X/HN8SXgVsGImJ6dioLIG1sA0oIISoDe4GVKQ3UNG2Y\npmkemqZ53L17N4ump1BkPn5+Minr3LmUxwghE4zqOQZIf4STE9s/f4/5F37C8MwIONc3rgxEKhQq\nJF/h4TJmPa39dxUSGxtYs0aW31i+XO67YFwNV9x5VqQEtG1L431+zGg+g01em5h1fBYgBSBXrwEA\nN4H4T/T2MftiEUKECCH0WqxLgRopnUwIsVgI4SKEcLFJLo5NoXhL8PGR29TaDnp6wo3LT/nRrzM8\nf871FXPo888oXIq6UObKbAwMkg/nTA7dCkjJ/aNInXr1ZIbv7NmyrIanJ9zEnpC/jsgelUOHMn7r\nXbqV68LH+z7meOBx5QICTgJlNE0rqWmaCdAL2Bp/gKZp8WoZ0hFIuJKiUORAdAG4eTPlMevXCZZo\nwykUeIaIVcvp7DkZQ82QDT024FTclMKFk+mDmwJKADLORx/JDOzNm6UA5MkDJavkk4vCI0agzZjB\n2g2C0mbFeHfDu5gXDOHxY9lq820kw4aiECJS07T3gT2AIfCrEOKipmlfAh5CiK3AWE3TOgKRwH3A\nLaPXVSjedF5mAQgBRksX0Vf8Bl98wXjj/ZwNPsvWXlspkb8EH38MN26k/Xp6RrASgFenUye5GD9z\npszIrlRJhntiYAQLFkDp0phMnMjJqxWp0NKHrVb9QdtGSIhBgpLdbw1CiDf2VaNGDaFQvK3Uri2E\nvM0L8exZ0s89l54QzzARAZXbiI3n/xB8jhi/e/wrX+/WLSHGjRPi+fMMTFoh5syR/2ZGRkIMH57M\ngE2bhDA3Fw/trIXzKAT1ZogLF7J8mimCfPBO0z1WZQIrFK8BIWT/kTx55Hu9rHMsISHYj+vObYrw\n8LfpDN4+lFrFavFt829f+Zp2dvLJ1cTk1eetgIEDZXmNyMgUrKmuXeHQISyFMe6/GtGi+BSO+Ltn\n+TwzAyUACsVr4O5dWd6hYUP5PoEbKDqa6L79yBMWzLwm6xl0YiQA67utx8RQ3b2zG0tLGDZM/pyi\nO61mTTR3d7Avx8510Vxf0o6Hzx5m2RwzCyUACsVrQPf/N2smtwkE4KefMNi9i3HMwq/bVk7cPMHS\njkspWaBkls9TkTxTp8L8+VC7diqDHB15sOUYu0zr8e22EI53dkG8eJHqeR8+hCdPMneuGUEJgELx\nGkgsALGRQMePw//+h0eJbqxwLsvmezMYWn0o3Z27Z8s8FcljZSXrwhm85A5ZwNGSzs8OsalefVrt\n8eNWgyrw4EGyY588gerVZcbxm4ISAIXiNeDtLTNyK1WS6wCBgcgbQ69eYG9P7+jvoGt/yhUqx6xW\ns7J7uopXJE8eMDIxxL3eIX4YXB4bDy8ialSTfwCJ+Ppr2eNh3z65RvQmoARAoXgN+PjIcgyGhrLk\ncGCAgCFD4OZNHi5ej1+98UQYhbC+23rymOTJ7ukqXhFNi8kGDjHgvZn76DTMkrB7NxGurrBzZ+w4\nb2/44QdZbuLevTenp7ASAIXiNeDjIytvghSAGqeXwJ9/wjffMP3+GSi3jUEOM6hSRAXtv+0ULCjL\nQRTLV4xhY1ZSbXAkt2zNoX17+PprRFQ0o0dLa+H33+Ux//6bvXPWUQKgUGQyERHS1NcFwCWvNx9c\n+xBatMB7QDvm+IyHKy2Y3GRs9k5UkSnELwjXpUIXWjcdStl3bxPcsSl88gmBtbtxcv8jvvlGRoVZ\nW8N//2XvnHWUACgUmcyVK7KWTLlywPPnjD3+HuHCgqeLF9Nncz8Moyww27OCEsXVf7+cQOKKoLNa\nzcLeriw1G3rz+NuvsfPYxjnTWgyrdxFNkzWHlAWgUORQ9AigcuWATz6h6O0zDOJXJp39hdNBpyl3\neQkVHYq+NMJE8XaQWADymORhdZfVBIffpq35BZqzjyLmoRjWqQVr11KvniwBfudO9s1ZR/0JKhSZ\njC4AzsH74ccfudZ6BNscCzDfcwaDqg4i5N8usYXbFG8/+hpA/MiemsVqMq3hNI6EruN8o1sYeZ6W\nMaB9+tDv2ChMefZGuIGUACgUmYyPD5S1DSXv6AFQtiyBkz+DLv2xNSnJF3VnExiIEoAchLW1XPcJ\nD0+4/92iUyCgDk+ajOKWVSTs3w8ffYTd5oW4a7Xx2Zb9oUBKABSKTMbbG+bxviwAtHo1C4KngtUN\nepuuIvCKJQAVK2bzJBWZht5eM3FfgF+XGmGw5TcMjaNw2+xGtJEh/PgjbNtGCcMAxqysAatXZ/2E\n46EEQKHIZCqc+50Wd9bAtGlssbzFOu9fMTj2MaZ36nHpkhyjLICcQ8GYds3xO4M9fw6//gqdGjgx\nu/UsDlw7wLwT8+SH7dszf6gnp0U16NcP3ntPFo7KBpQAKBSZyL1zt/ghfCRBjq7c+WAIQ7cNpWqR\nqjhc+ZzAQLh0CczMZA9gRc4gOQvgzz9lwtfIkTC42mDal23Px/s+xuuu7IVVqY09TcR+rg3+Cv74\ngxfOVQhccyjL564EQKHILIQgetBgzHhGwNcrGb57NI+eP2J1l9U4FDWJFYDy5dPe5Uvx5pOcACxa\nBE5OshaUpmks6bCEPMZ56L+5Py+iXlC3LkRhxNSnn/BhraNcCzKhaN8m8OGHWVotTgmAQpFZLFmC\n7andTNa+x7OsO5u9NzO96XQq2lakWDFiBUC5f3IWiQXg4UM4fFh6d/RQ3yJ5i/BL+1/wuOXBN0e+\nwdpa/h06dCndAAAgAElEQVSsXQvrrtSif6WzLDYcBXPmQNWqcPRolsxdCYBCkQoPHsCyZWko3uXv\nD+PHc7pgMw64dmDC/jE0cGzAuNrjAFkO4sYNuH5dCUBOI/EagIeH3Natm3BcN+du9K3cl+lHpnPq\n1ikWLIDly+XfRM9BeRgZNY+Hf/4jQ4o6dkwaVvQaUAKgUKTCihWyhpu+eJss0dEwcCDC0JA+z5cS\n2mQIUdFRrOi8AkMD6euxtwe9VLwSgJyFiQnkzRtnAZw4IbcuLknH/tz6Z2zz2DJg8wBc6z3DzU2u\nCTk6ys+vFG8K587JJvR5Xn+RQCUACkUqeMk1Oy5eTGXQzz/D4cPcnDAbb+edBJru48eWP1KqQKnY\nIcWKxQ1XIaA5j/jZwCdPQpkyUKBA0nEFzAuwrOMyLt69yGcHPovd7+AgtwEBQL58UKfO6580SgAU\nilTRy7pfuJDCgMuXYcoUaN+eVYUaQIuJ1C/SkuE1hicYZm8vtyYmUKpUMudRvNUULJjQAqhZM+Wx\nrUu3Zlj1Yfxw9AeOBkhffwIByEKUACgUqaALQLIWQFSU7CBubk70ooX8fGMQmjBmTc+laJqWYKgu\nAOXKgZHR652zIuuxtpZrALduye5vtWqlPv7Hlj9SPH9xBmweQHhEOLa28uHgxo2sma9OjheAVq3g\nu++yexaKt5GQENncHVIQgNmzZbTG3LnMubGB22ZHeCdwDo75HZIMLVJENg9R/v+cie4COnlSvk/N\nAgCwNLVkeafl+N33Y8o/UzAwkA8JygLIRMLCYO9eOHIku2eieBvRi7pVqwZ+fjK7MxZvb9k5vHNn\nfFrW4H///A+8O9LNqX+y5zI2hgkTpMGgyHnoLqCTJ2WOR7VqLz+mcYnGjK01lrkn5nLw2kEcHJQA\nZCrnz8vwvcDA7J6J4m1Ed/906ya9PbogEBUFbm6QJw9R8+cxYIsbxpoFbP+FOnW0lE7H999Li1SR\n87C2liHDx49D5cpgbp62475t/i2lC5Zm4JaB2BUPUwKQmXh6yq0SAMWr4O0t/bLt28v3sW6gn34C\nd3eYN4+frq7B/aY7raPmo4UXwdU126aryEasreXD5r//vtz9Ex8LYwtWdFrB9dDr+BSfyM2b8vki\nq8gVAnD/fpZmVytyCN7esrF7hQpy4fbCBWRc6LRp0KULl5pV5tMDn9KtQjfCT/SkQgWwssruWSuy\nAz0b+Pnzly8AJ6aeYz0+qvMRZwx/Iar4XoKCMn9+KZEpAqBpWmtN03w0TfPTNG1yMp+bapr2e8zn\n7pqmlciM674MXQBAWQGK9OPtLev2mJjIuG6v85Gxrp/I+XMZsMWNfKb5mN92Ae7HNWrXzu4ZK7IL\nPRsY0mcB6HzZ5EvszcpDp8F4+T/MvIm9hAwLgKZphsB8oA3gDPTWNC1xrMNg4IEQojQwC5iR0eu+\njOhouQZQqZJ8n9W+NcXbzfPnsrdv+fLyfcWKUPvoTBnkPW8eM3xX4HHLg4XtFnJ4ly0hISgByMXo\nFoCFxatFepkbm/Nd7RVgeZNvT3+UqXNLjcywAGoBfkIIfyFEBLAe6JRoTCdgZczPG4FmWuJA6Uwk\n4GEAnt5hhIfH+W+VBZB7iYpKv1/Vz08+ROgC0MjWi7Eh04jq2IXzTSryxaEv6PVOL8TF7vTuLW/+\nvXtn/twVbwe6AFSv/up5Hu2quMJ/kzjwcBm7fHdl3uRSITMEoBgQ//k6MGZfsmOEEJHAQ8A6E66d\nhAdPH1BlURUm7/sYgHbtYialBCDX0rs39E8+OjNF9Aig8uWBqCh67x1IOHnwHP0zA7a4UdC8II2f\nzKNXL3nz37NH1oNR5E50AUiv/z8+VlaQ99TnFIysyJBtQwiPeP3F4N64nERN04YBwwAc9QpJ6aCA\neQEGVRvET8d+wqB0V2rUaE6hQsoFlJs5ezbtYXk6ugCUKwfMnIm1rzu9WUuE96+ceXCGL53/YlQv\naxo0gO3b1c0/t1OwoMwL7Njx1c+haeBY1BTbKysZNdWfPCZvRzG4m0D81Ef7mH3JjtE0zQiwAhJ1\n0JQIIRYLIVyEEC42NjavNKGvmnxFnqflMOwymAjtEfb2ygLIzQQHw5076TvG21tmZuYN9IZPPyW6\nUxc2FivP5vtf0bNCH1ZM7kypUrBjh7r5KyQffAAlS2bsHA4OEHa5Bj0q9sicSb2EzBCAk0AZTdNK\nappmAvQCtiYasxUYEPNzd2C/EC+tsP7KmBubk2fvCiItApnw9wQcHJQA5FbCw2VG+N270qefVry9\noWL5qHhRP7Mx6uGG8YtCWJ/4GX9/WLIkSyr2KnIRjo5Z663IsADE+PTfB/YAXsAfQoiLmqZ9qWma\nbhAtA6w1TfMDxgNJQkUzk/v34c7p2jQ0msiS00uILrVbuYByKXpMdVSUzNRMC0JIARj5JC7h6yuf\nJTzLfw6DHUtYNKsgw4ZB48avbdqKXIqDg7RWnz3LmutlyhqAEGInsDPRvmnxfn4GZI1Ng+ynADC+\n+ufcvbaNIwzh0ZMLPHmSHwuLrJqF4k0gflLNnTtxi3UgrcLg4KSNO27dAvvHXrQ7IRO+PBqW5ttl\n/aiGG2c821O0qCzroFBkNnpZ6MBAKF369V8vR2YC6wlgtaqbsaLTCh4TDK3GcTPxyoQix5NYAOIz\nbRp07pz0GO8LkazAjWiLvDybO4sBW9wokrcIU11mAbBwocr4Vbwe9LiXrPJY5FgBsLWVJXhrFqtJ\nb4fJUG0Ff5zdnuz4p0/h0aMsnqQiS4gvALdvJ/zs+nX5eeIcAfP5P+LKCR5/N5/PLi3g0t1LLO24\nlK5t8xMQkLFID4UiNXQLIKv6AuRIATh7FqpUiXs/pe40CK7MDz5DCXmSNPjogw+gWbMsnKAiy0jN\nArh1Sy4M6zX/AbhwgVo7P+NPrRvebR348diPDKk2hNalW6NpcY1dFIrXgf73pSyAV+TFC1m1Mb4A\nlCpuAptXEhZ1jzG7xiQ55vx5OHVKRowochZBQbIfr6YlLwAQzzJ48QL69+eJsRWf2/+E21Y37PPZ\n81Orn7J0zorci7k52NgoAXhljIykAIyJd583NwfrF1WpETaNdRfWsfHSxgTHBATIyI8U+74q3lqC\nguRTVaFCCQXg8eM4t19wcMzOb76BM2eYVXYRd5rOwve+L8s7LSefab4sn7ci9+LgoFxAr4ymydXz\nxEnE9vZgc3kyLkVdGLF9BLcfy8e+yMg4N8HZs1k8WcVrJygI7OzkmlB8AdCf/iFGAM6cgenT4b33\nWFnQmtsl5/B+zfdpWrJpls9ZkbvJys5gOU4AUsLBAW4FGLOy80oeRzxm2PZhCCFi/cCQsHy0Imeg\nC0DhwikLwN2AZ9CvH9jYEPbjN1yv5ka+SCe+a66aSSuyHkfHtOesZJRcIwB6w2VnG2e+afYNW322\nsspzVaypZWSkLICcRkSE7NP6MgugxuZPpd9w2TI+dJ9OtOUNuhutypJaLApFYn76KesqF+QqAQgJ\nkSGfH7h+QAPHBozdPZaz/tLWatRIJpBlZTs2xetF9+0nJwB6TkgHq8M0OvUTDB/ODqdofvVcCkcn\n4mpXN+snrFAAxsbSlZ0V5CoBAPkf39DAkBWdVxAtoplzfSBo0XToIKOArlxJ/vhr12T25+urYKTI\nbPS1HV0AHj6UjV5AWgBF8oSx6NkAgs1KEvLlFIZsG0Jpy0pw4Avs7LJv3gpFVpFrBEBPsNAXV0oV\nKMXMljPxi/4H04bzaNhQ7k/JDTR/Pnz8MSqb+C0isQBAXMz/rVvws+E4ijy/zsQiKxl1eBL3ntxj\nlN0qiDJVAqDIFeQaAdAtgPi+tSHVh1D4YVsiGn6MYWFvjIxSXgg+dkxulQC8PSQnALobyOncX/R4\ntIy91T5mi911/rj4B182/hLzh1Vjj1Eocjq5WgA0TcP2+FKMoi0YvKMf5Z1fJGsBRESAh0fS4xVv\nNkFBYGAgb/4JBCAoiAmXh3K1QHX2tx9CeKPR1ClWl0n1JhEUJP2v+niFIieTawTAwkJ27UkcXxvk\na0ejsF/wuOWB1virZAXgzJk437GyAN4egoLkjdzQMJ4A3BaIgQMxi37Chi6/sdV8GBhE8n3dVRga\nGBIUJJPGjI2zd+4KRVaQawQAZHzt1atx758+hXv3oJFNd/pX6c+Fgl9zy+BYwtowwNGjcmtgoCyA\ntwk9BwDiBKDYX/PQ9uxhAj9yrOzfeEfsh92zMXvilOQYhSKnk6sEoGpVOH06LpJHv5k7OMDPrX/G\n1tQBuvbj2KmwBMcdPQrFi0OJEsoCeJsICpIVYUG2bXQxOUfD7RN51KAtC23qs+P5ZBrYdoDTg2ND\nRoODlQAocg85TwCEgAkT4PDhJB+5uEgfsO4G0rcODmBlZsXSdr9BAX++PjUuwemOHoW6dVG9hV8z\nQsC//2be+eI/zWtPn7BG9CbcpADHRi6E7n2xNM7PnGbLAC22IJyyABS5iZwnAA8ewNat0KQJfP65\nLPYTQ82acqsv6OoCoNcNal+pAZbnPuZE5DI2XdoUO+bWLahTRwnA6+bAAWjQAE6ezPi5oqJklc/Y\nm/n48ZR9cYnvK65iZtBsKHyeH+r/SgVHG0A++UdHJzpGocjh5DwBKFhQ1nbu1w+++EIKQUy9h8qV\nZcmHxAIQv8Z7g8gvMA2pwdBtQwl8FBjr/69bV5YVvnlTJYO9LnQ3zPXrGT+X3gTezg7480/45Rc2\nlprEhoIaf4fNghOjea9mW8zMIH9+ee179+TzghIARW4h5wkAgKUlrFgBq1fLzK5q1WD7dszMoFKl\nhAJgYwNmZnGHdmxnwvO1awl//pz+f/Xn6LFozM2leNjby2igkKQ9ZRSZwMOHcpu4c9eroOcAOBlc\nhcGDoWZNtjQci3/VfhSIrEABj+9j/92LFJHX1I/R1w0UipxOzhQAnT595KqvoyN06AATJ+Ja4wUe\nHvIp/saNuAxhnSFDoE7Zshjv+5kD1w7w5+0fqVVLhgUWKybHKDfQ6yE0VG5j6/NngKAgMCaC+nN7\nghCIdes45jCcaJP7VPZdRzFbi9ixRYrIa8ZPHFMocgM5WwAAypSRabyjRsGPP/L5/kZYPAjE319a\nAIkFwNAQli6FCPdBFA3tzs2yUylR7wSQsJ6QIvPJbAH4nknk9ToJv/7KvHs7uWK4A/b+wK3TVWLF\nHGSp6ODghMXjFIrcQM4XAJA+nvnzYf16CgWf5wzVCPh1b7ICAODsDJ9M1bi1aDGEFWVP3t48ev4o\n2WxiReaRmgDs3g3PnqX9XPn++YsPmUPkqLGcq1eaiXsnUtWiHbiPwc8PihaNG5vYBaQEQJFbyB0C\noNOzJ9HuHtzRCtPwm1Z88OhLHIpFJzt08mR4p3QB2LSWuy+uM3z7cGxthUoGe43oawCJBcDPD9q0\nga+/TuOJfH1pv8mN04YuPP/uM3pt7EUB8wJMcV4OaAiRVAAePQJ/f8iXT2aNKxS5gdwlAIDxO+UY\nXcOdjWZ9+ZLP6Pt7e7h/P8k4ExPYtAmWf1mPLxp/wfoL6/ntwnLs7JQL6HWRkgWgZ28vXAhPnrzk\nJOHh0LUrkcKIj0tu4P39H+F9z5vVXVZTtphN7LDELiCQJT/U078iN5HrBADgHdc89Hy2kpEsoMiF\nfVCjhlwsTkTZsuDmBpPrT6ZpyaaM2TWGguUuKQvgNaELwO3bCUNt9XDdkBBYtSqVEwgBQ4fCxYt8\n4rSOWzUPs+LsCj5p+AnNSjVLUOAtsQUAcOGCigBS5C5ypQDIhDCNRYzkzsYjMvi7bl0ZOpoMhgaG\nrO6yGksTS67V6s6NoPCsnG6uQXcBvXiRsCdqQICs0Fm1KsyaFdfDOQlz58K6dTB9OhtNHblcZhSN\nijfis0afATLkVyc5AXj+XFkAitxFhgRA07SCmqbt1TTNN2ZbIIVxUZqmnY15bc3INTMDFxe5NTCA\nQu1c5dN/vXowcKCMFoqISHKMnaUda7quIczUG3/nkQiVDZbphIbKFA5I6AYKCJBumkmT4PJl2LEj\nmYP374fx46FjR8LHjyWo3rsYa+as6boGQwNDQIbyFiwohycnAKAEQJG7yKgFMBn4RwhRBvgn5n1y\nPBVCVI15dczgNTNM+fKQJ4/8z25khHw03LMHJk6UjubGjZN19Dcr1Yzmxp/xwvk35h1d9krXjo6W\neWmrV2fsO+REQkPlvw0kFQAHB+jeXW5nzkx04JUr0KMHlCuHWLWKoVvfR9hcoJ/FGorlK5ZgqK2t\nFH7d7w/yn1/vwaoEQJGbyKgAdAJWxvy8EuicwfNlCYaGsrZPuXLxdhoZyaa/GzbI7vA1aiRbUG5A\niU/gSnMmHhjDmaAz6b72zZsyOfnUqQx8gRzI8+cyzFP/N0lOAIyNYexYOHgw3u/v0SPoGPNMsXUr\nS/3+YJ3XSjj4GY0dWia5jq2tvPkbGcXtMzKSPQBACYAid5FRASgshIiJniYYKJzCODNN0zw0TTuu\nadobIRJr1sDatcl80L07nDgBVlbQtCnMmZNgRdLRwRD+XIOloTXd/ujG/adJI4hS4/JludUXPBUS\n3f+f2AIQImHC3tChMlRzxgxkxbc+fcDHBzZs4LTFQ8bsGoNLgZZw+JNkF3Tr1iW2/3N89LFKABS5\niZcKgKZp+zRNu5DMq1P8cUI6xVNyjBcXQrgA7wGzNU1zSuV6w2LEwuNu4s4smYj+JJgszs5SBNq1\ngw8/hL59Y+MPixUDwm0ZUXAjgY8C6ftnX6JFSquSSdEFIP4iZ07i5ElZjDW96IJYvLgMwdUFIDQU\nHj+Oq9hqZQXvvw8bN8J9t/GwfTv8/DMhtavQ/Y/u2OaxZUiBNSAMk72Zf/strF+fdL/+t6AEQJGb\neKkACCGaCyHeSea1BbitaZodQMz2TgrnuBmz9QcOAtVSud5iIYSLEMLFJn7YRlZjZQV//QXTp8vI\nkjp14MqV2Phx07u1mdN6Drv8dvHVoa/SfNqcbgFMmQIjRqT/ON0CyJ8/rjYPJOzZoDNuHEwwnk3B\n1T/D+PFEjRhO7029uRl2kw09NhB+V/pz0hPSqY9VYaCK3ERGXUBbgQExPw8AtiQeoGlaAU3TTGN+\nLgTUAy5l8LpZg4EBTJ0KO3fKO5GLC2b/7MDaWvryR7iMoH+V/nxx6Au2+WxL0ylzsgBER0sLICgo\nDQlbidB/H7oA6BVBkxOAQkf+4ruI8fxJV/yG/8D//vkfe/33sqDtAlztXQkKAlNTqeFpxckJChSQ\nL4Uit5BRAfgOaKFpmi/QPOY9mqa5aJq2NGZMBcBD0zRP4ADwnRDi7RAAndatZQ3pEiWgfXumG33O\nzYBoNE1jUbtFVLOrRp8/++B11+ulp/Lxkduc6ALy8ZFrspCw93JaSCwAKVoA//4L771HZPVaDDH9\njaFzN/L90e8Z6TKSwdUHA3FtHfXInrQwcaJcWE7PMQrF206GBEAIESKEaCaEKBPjKrofs99DCDEk\n5uejQohKQogqMdtXi5/MbkqVgv/+gwEDGHH7CyYdliUkzI3N2dxzMxbGFnRc35GTFx6k2DAmIiLu\nxpgTLQB397ifr1xJ37GpCYCRUYxrxtMT2rcHR0dMdm+j1UgfDuYbSA2busxuPTv2XMHB6Xfl5MkD\nJUum7xiF4m0nV2YCvzIWFrB8OWvqL6Rm2D9QvTp4eOBg5cCmdzdx7cF1as3oxdbtkcke7u8v3SRO\nTvJJOSoqi+f/mjlxQrpeQH7X9KCvAVhZyZv33bsyQTsgQCZtGV71g1atZKbY3r0Em0dxqFhHeGpN\no9ubMDE0iT2X6uurUKQNJQDpRdPwbzmC+vyLiBYyg3jhQuo51KXitQVQ+m/+d2h8sofq/n9XV7nV\nb3o5BXd3+euwtHw1C8DAAPLmlRE5QkgRCAiAGrYB0KKFVMy9e3lqZ0Pn9Z15GHEfx/+2Euid8HH/\nVSwAhSI3ogTgFSheHDyoyYlFp2WuwKhRhHfuw9UVPdGOjeeS5Vx+dp+b5DhdAPTm9DnJDfT0qcyf\nc3WVFk56LYDQUOn+0bS4m3dwMLy4GsgC7yayYuuuXYhy5RiybQjuN91Z3WU1Fa2r4ucXd56ICFk0\nTlkACsXLUQLwCnTuLJ9Sx39tjdi+A6ZPx3zb75wQLswr2Re8OzJu94fsuJywaM3ly7LsgO5rzkkC\ncOaMdNnoApBeC+Dhw7ioHV0A7p+/yYobTbCKuAt//w0uLkw7MI2159fyddOv6VKhC6VLg69vXK6e\nHj2kLACF4uUoAXgF8uWTzUmOHoX1fxgQMXEqXa32U8g0jJEr6jLijyYUoQo9N/ZMUC7i8mVZYjp/\nfvk+J0UCnZBdM6lVS66XX72aStXOZNAtAJA3b3sCqPZRE2zFbbaN3gOuriw9vZTpR6YzuNpgptSf\nAkDp0hAWJt1FoLp6KRTpQQnAK+LmJteAJ02Shd22hDbCc8VZtIYNWRg9jt/m21Ey2oo2a9pw9YEM\n/bl8Wda60WPNc5IFcOKEDNW0s5MWQERE+hrnJBCAR5f5l/qYhd6mNbsxbVSbXb67GLF9BK2cWrGw\n3UK0mHjN0qXlMbobSI8eUhaAQvFylAC8IoaGMHu2bA85cqR86m38ri3s2sWe5j/Q4O7feCyIxsU3\nnFarW3H19l2CghJaADlJANzd5dM/yN8FpM8NFOsCOnsWi1YNsNCe0sPmIMeoyyPLk/TY0INKhSux\noccGjA2NY49LLAC6BaAEQKF4OUoAMkCDBvDuu/Jpd8QIGcWCgQFWX02gLkeJEHnZtiSc4Ruu0uW3\nNmDyOEe6gO7dk4u+ugA4xVR6Ss9CcGgouD49KEtxm5rSx+EIO4OqQSEvPjzZBps8Nux4bweWppYJ\njitRQv7eE1sAKdZ5UigUsSgByCAzZ8KwYbJKpU7NmnDVuibjG59BGzqUj45EsuLHU1Rs1ZziTs+w\ntJQ3rZxiAej+fz281cFBWkjpsQDa3V3OxL0tZLW9f//lqWM5sLoO/VtgYmTMvn77KGpZNMlxJiYy\nKiu+BVCokCwdrVAoUkcJQAYpVgx++SXuqR7kza91a9i8Ly/RC3+BLVsoGWbJ6R3unP+qCi8inpA/\nf84SAAMD2UIB5M23ePE0WgDR0URP/h8Lnw3iWonGMtva0ZH8xW5Dv5YYmIazp+8enAqmWECW0qUT\nWgBqAVihSBtKAF4TbdtK18g//wAdO/Jx6yvstKnBgI2XCXC2p5bFmRzjAjp9Wtbxz5s3bl+aQkFD\nQ6FzZwxmfMtihrJj1E7In5/bj29ztExTyHeTqpd2ULlw5VRPk1gAlP9foUgbSgBeE23bgr29LF0z\nbx54XLdhYRUPtk8fgGXwA7berEHH4x/LDKosIjwcJk+W28zkzh35XeNTqtRLLABPT9mcedcuQqbN\nYTi/kM/amDvhd2i2qhlhRtdgzQ7esar70uuXLi3XU+7fV2UgFIr0oATgNZE/v3wybt4cxoyRlSbL\nlYP2U1ewfsM0fqsi6On/PeKdd2D37iyZ0+7dspPWgQOZe974IZw6Tk4yIzdJuQshYMkS2V/h6VM4\ndIgbnccCGuS5S/NVzfF/4M/YQtvheqMEZaBTokwZufX1VRaAQpEelAC8RmxsZMOqmTOlX7xuzMPs\n2LZfMKfWTJoMgFtPb0ObNtCpExe3Xkl3GeX04BVTrTp+v93MIDkB0ENBE1gBt2/L/r3DhsmiQadP\nQ926UiTyBTDtagP87vuxrfc2GhdvApAmAdBDQU+elBFZygJQKNKGEoDXjKbJDlZhYdCzZ9z+WtHj\nOH1zHqUGh7O0ZxnE/v2U6ezMqRaTX9vqsLe33GaFAOihoFeuIJ/6N2yASpVg716ZQLFnT2ys5qXb\nvjCoPg9eBLGn7x6alWpG+fKyDHTVqi+/fsmS8vf877/yvbIAFIq0oQQgizA1TdhsJH9+ePHfaBZ1\n/ZURzv60/bQUfxh1ouuV7xGlSsFPP8GzZ5k6B90C0JOlkkMImDVLulPSwrNn8Px5yhZAyEl/uSDy\n7rvycf7UKfjgg5ikCTgTdIYplxuA8RPWtDxAg+INgDi/vh5amhpmZvLUR47I90oAFIq0oQQgm8if\nX7rA33MeyOZemzkY4Uu/EWeobrmV55VrwYQJ8i44d26CheJ799JXYkEnOjrOAkhNAPz8YPx4mD8/\nbeeN38glPvm0ML43/4yBP1WUoZ2zZ8t04YoVY8fs9N1Jg+UNMBDGsPww9Z2qJzhH/Kiil1G6NNy6\nJX9WLiCFIm0oAcgm4tcDal+2PXNd/gHz+3iOGMhPQ6fI+NFSpWDsWKJLluJolx/o0CCUwoXl0+67\n78qH6bQSEBDXpzc1F9D+/XKb1nMnEYCICBn25OTExKdfcrRQR2l6fPCB9OnEsODkAjqs60BZ67IM\nEu5wrwL58qX9+yRGXwcAZQEoFGlFCUA2kbgeUP7HdWDpcXhqzTTf5iy28oPDh+HgQS5EOVN38yR+\n/8+e/6q9zw9DfNizR0ZRNmsGf/wh3TCpobt/HBxStwB0AThzJm0dy/T5W5uEydVuJycZ9lSxIp+2\ndGeg+e8yWy6GiKgIxuwcw+ido2lbpi2HBx4mOrQoefMm0Id0owuAuTkZEhKFIjehBCCbSCwAN24A\n98tQbNdxCj5szvDtwxm9YzSh1Wvj+vgfvnv3NBb9u1P7/BI+WlKeEOf67Oy2jKDLYfTsKePwf/gh\n5evpAtC0qbQAkutbHB0tQ0QtLWWugN7APjVeeF7iBybQ1M0BPvpI3ol374b9+7FuU4tr1+LWE26F\n3aLJyibMOzmP8bXHs7nnZvKa5OXhw6QupPSiC0CRIqqxu0KRVpQAZBO6C0jPBg4IkI3JWzTIj7Zu\nOx/VmcACjwXU/KUuzyz8qOJWDVaskEoxYwZGD+7RZtMQLt6zJbhuF8ZZr+KbSQ8ICUn+et7eULCg\nDMR59iz5dpQXL8q6+iNGyPcpuoECA2HBAqhThwYjKvIBc3hSt4X08R84IHv3ahrdusnhGzbAwWsH\nqQC9FFYAAA9sSURBVLG4Bp7Bnqzvtp6fWv2EoYEhkHwUUXrRBUD5/xWKtKMEIJtIzgJwdJT1dO7e\nNuRD5x/Y2msrgY+vwvDqBNusRQghQycnTZKP9P/9hzZ0KIWvn+R/PgO4RyHMGrnClCkyzDKeGnh5\nQYUKcTfI5NYBdPfPyJFSjGIF4OFD+VT/6adygg4OMHo0PHrE0W4/UoybhK/YEFcONAYHB6hV5zlz\nLk2i6cqm5DPNh/sQd3q+0zPBuMwQAD3sVPn/FYq0kwGvqyIjpCYAAB4e0LlzBxx3nuV2/d4M2tGH\nbVc2sqDdAorkjfFz1K0rX7Nn473agz8GbGdU1H7y/PgjfPedPJGjI1StSu+TTuSvVpKK/sWpR0Ee\n/WcF5vnkeaKiIDKSwE33GVLkLiUP3GFBAT+Kr/aGv72l+SCEDN10dZXn7tgRypfn8AyNu5uSv4Gf\nv32ewDb9uRN9lt5lRrCk+4/kMcmTZFxoKBRNWugzXVhYyAY91apl7DwKRW5CCUA2kbgnQECATHqq\nUkVWEz11Sj5QXz7pyDfdDmFUfxafHvgU5/nOzGo1i35V+mGgxRhwBgbYtq/FZ9TCctiXjBv6WLpj\nTp+GM2eIPO3JgGd7sTj2FI7BvwBDks4pdglhMPQxMMJPOCHqlkPr1Utm7rq6JonNDA2VJZnNzOL2\nhUeE8+WhL5l5fCZWJgXg161UcutAHpPkfxcPH4Kz8yv+IuPh4aH8/wpFelACkE2Ym8vksNBQGcFz\n+7Z8WLewkDfDU6dkH3SAtq2NqFJlIh3KdWDQlkG4bXFj0alFzGk9h1rFpNulQAF5b75+HflDs2by\nBRw7Ag0bCvauuYtrket0bRbK2P6hdGj4SN4xDQzwv27I2M8LMPYrG1q+Z8Pagw70H2zMxe9Svznr\n7htNAyEEf3n/xfg947n+8DqDqw1mRvMZtPvLmg0bpGcqtXNkFHXzVyjShxKAbETvCRAYKN/rdW9q\n1IAdO2SLxMKFoXJMNeTyhcrz76B/WXl2Jf/b/z9cl7rSp1IfpjWaRlnrshQvDteuJb2OTADTcKpj\nS94StvxrBlVtocPguDEbZsAOYNlQoDDUiElCPnUqbQJw4OoBJv8zmRM3T1DRpiKH3Q7HZvX26CHz\n2q5ckb56d3c4eFDuMzCI1w5SoVBkKWoROBvJn1+6gG7ckO8dHeXWxUVG42zZAi1bJnyyNdAMGFht\nIJffv8zkepP50+tPKsyvQO9NvSlY4by0ABLh5SUtjuLF5bmKFEm6CLx/v0zS1VsplisnF4I9PFKe\nf7SI5rK2jaBWTWi6qim3wm6xrOMyzo44G3vzB+jeXW5Xr5blqOvWlduVK2W4aVRU5lgACoUifWRI\nADRN66Fp2kVN06I1TXNJZVxrTdN8NE3z0zRtckaumZMoUEA+QQcEyPfxLQCQFSBatUr+WEtTS75t\n/i3XPrzGhDoT2OazjSPvVOa8S0NWn1vN0xdx5SO8vOQNPab8DnZ2CZPBIiJkIbWmTeP2GRrKNYnk\nQkGDHwcz5/gcKsyvwJnyHYnI68fMljPxHePLoGqDMDJIaFgWLy7XMz7/XJajHjQIateGqVPjvrsS\nAIUi68moBXAB6AocTmmApmmGwHygDeAM9NY0LROW/N5+dBeQbgHoTVX0hWCAFi1SP4dtHltmtJjB\n9Q+v09Z4BlHmQfT7qx92P9nRe1Nv1p1fx8UroVSoEHdMYgvg/HlZJqJ+/YTnrlFDZgRHRgr8H/iz\n+NRiWv7WkmIzi/Hhng+xMrWi6NF1dLjiz7g64zAzMiMlxo6VYai7dsl2ALNnyzn873/yc+UCUiiy\nngytAQghvAC01FffagF+Qgj/mLHrgU7ApYxcOyeQP78svhYQIHsHmJvL/ebmMmHLwABsbdN2LmsL\nawaUnsTOqRNZ+s9BjoatZrvvdtZfWA+9DdhvUJGhW11xKepCpKMTgZ6OPH3hgJmRGWfOyH+/KlWj\nCHkSyr0n9/C970uw0yWetLpA8VmHufVE+pZKFSjF/+r/j96VeuNs44zdNCjY8eXz69NHvnRcXeG9\n92Dt2rjfhUKhyFqyYhG4GBAQ730gkIYivzkf3QWk5wDEZ+3aOCsgrRQvDqBhG96EZZ2a8P/27j+2\nrrqM4/j707W4CjNjMOy2buskc5shBkkzaVgUceJEfojRBDEhKmbBSMQ/RAwjgpJBDGhMDH84gSjJ\ngJCwBRKn/BCIGDZg4JAfG4Y4BpvDijIdIWRue/zje0/a3d67ntt76em59/NKmt5ze3fPc9b2PP3+\ner6H4zB3/OFJvr7298z5/FNs2LGBW/98KxwPXALvvwGE6Ipj4Opult5VY6/IRXOZw8e5+nNXctai\ns1h64tIjEn4zM3huvBE2bEgrk50AzCbfuAlA0sNArfWVayLivlYHJGk1sBpgQfVdsc2M7gJasuTI\nr43usslrYCB9zgaCu9SF9gzBY0OsvwWWLQt2/WcXt6zfxc2/2sWV1+9m+nHvctuvD6Bp/+Obl8xg\nVu8sZvXO4uTjT+bDs5Yxf/ZMPvkt+Pbysed7993mbt4LFqTyQWvXjgw+m9nkGTcBRMTKJs+xBxi9\nsV9/5bl651sHrAMYHBysUbKsfcycCQcPpm6glc3+L5O6i6ZP54iZQFu2pOqYS5emrrqBmQOcOTDA\nzc/Blz6Y+vl/ei5ceilcd+bY95w/f2SgtlpWT6iZv96vuw7OOy9rvZjZZJqMaaBPA4slLZJ0DHAR\ncP8knHfKywrCHTgwtgtoIqT0PqPXAmzenGbgdI36Tmf1cvbuTcnnnXfql1Do7x9Zp1Ct3mYwjeju\nzrfrl5m1XrPTQC+UtBsYAn4r6YHK83MlbQKIiIPA5cADwHbgnoh4sbmw28PoG2eezc/zGBgYaQHs\n359m+AwNHfmarCDc3r1plg8cPQHU24GsFQnAzIrT7CygjcDGGs//HThn1PEmYFMz52pHo2+crRru\nWLgQtm1Lj7duTTX+qxPASSel1sIbb8DOndDTU3+177x5aavFQ4fGDko7AZiVm1cCFyjrAoLWtQAW\nLoTh4dSts3lzeq66i6W7O007zVoAp5ySCrrV0t+fximGh8d+zQnArNycAAqU3Ti7u1tXxz6bCfTa\naykBLFmSNoKp1tc3kgCOVkI5W5xWaxzACcCs3JwACpTdOPv7G5/zX082m+bVV9MMoOrun8ycOanM\nw5tvHj0BZNv51hoHcAIwKzcngAJl5Q9a1f0DIwngkUfSzb1eAujrS3370FwLoHovADMrDyeAAvX0\npNL9rVzvNndu6lK6++50fPrptV+XzQSSUu2hembPTnHWSwDZXgBmVj7eD6Bg11wzZivdpkyblloU\nO3fCjBmpxHMt2ZjD4sVjNvk6QldX6gaq1wXk7h+z8nICKNhVV7X+PQcGUgJYvrz+2ELWAsizh+68\neUdvAZhZObkLqA1l4wD1+v9hJAGceur471dvNfC+fS7jbFZmTgBtKEsA9fr/IZWbHhqC83OUcs4S\nQFRVZnILwKzc3AXUhlasSN1AZ5xR/zUzZ8ITT+R7v/7+VPXzrbeOXFPgBGBWbm4BtKGVK9MYQKtu\nztlagOpuICcAs3JzArBx1VoL0OxeAGZWPCcAG1etBNCKvQDMrFhOADauvr602Gv0WgCXgTArPycA\nG1dPT0oCo1sATgBm5ecEYLlUrwVwAjArPycAy8UJwKz9OAFYLtX1gJwAzMrPCcBy6e9PM3/270/H\nTgBm5ecEYLlkU0GzVsC+fWlwuLe3uJjMrDlOAJZL9Wpg7wVgVn5OAJZLrRaAu3/Mys0JwHKp1wIw\ns/JyArBcenvhhBPgppvSLmKPPea9AMzKzuWgLbcbboDHH4dDh+C00+Dii4uOyMya4QRgua1enT7M\nrD24C8jMrEM1lQAkfVnSi5IOSxo8yutelfS8pG2StjZzTjMza41mu4BeAL4I/DLHaz8VEW82eT4z\nM2uRphJARGwHkFcDmZmVzmSNAQTwoKRnJHkY0cxsChi3BSDpYaCvxpfWRMR9Oc+zIiL2SDoJeEjS\njoj4Y53zrQZWAyxYsCDn25uZWaPGTQARsbLZk0TEnsrnYUkbgeVAzQQQEeuAdQCDg4PR7LnNzKy2\n97wLSNKxkmZkj4GzSYPHZmZWIEVM/I9sSRcCvwBmA/uAbRHxWUlzgVsj4hxJHwI2Vv5JN3BnRKzN\n+f7/BHZNOMD6TgTKPCOp7PFD+a/B8Rev7NfwXsW/MCJm53lhUwmgrCRtjYi66xamurLHD+W/Bsdf\nvLJfw1SI3yuBzcw6lBOAmVmH6tQEsK7oAJpU9vih/Nfg+ItX9msoPP6OHAMwM7PObQGYmXW8jkwA\nkq6X9JdKddIHK9NWS0XSTZJ2VK5jo6RSbdCYt5LsVCNplaSXJb0i6QdFx9MoSbdLGpZUyrU4kuZL\nelTSS5WfnyuKjqlRkqZLekrSc5Vr+FFhsXRiF5CkD0TEfyuPvwN8JCIuKzishkg6G3gkIg5K+glA\nRFxVcFi5SVoGHCZVkv1eREz5MuGSpgF/BT4D7AaeBr4SES8VGlgDJH0CeBu4IyJOKTqeRkmaA8yJ\niGcrC0yfAb5Qsu+BgGMj4m1JPcCfgCsiYstkx9KRLYDs5l9xLKlYXalExIMRcbByuAXoLzKeRkXE\n9oh4ueg4GrQceCUi/hYRB4C7gQsKjqkhlRpc/y46jomKiL0R8Wzl8X5gOzCv2KgaE8nblcOeykch\n96COTAAAktZKeh34KvDDouNp0jeA3xUdRAeYB7w+6ng3Jbv5tBNJA8DHgCeLjaRxkqZJ2gYMAw9F\nRCHX0LYJQNLDkl6o8XEBQESsiYj5wHrg8mKjrW28a6i8Zg1wkHQdU0qe+M0mQtJxwL3Ad6ta9KUQ\nEYci4lRSy325pEK649p2U/gGqpiuBzYB176H4UzIeNcg6WvAucCnYwoO5rSikuwUsweYP+q4v/Kc\nTaJKv/m9wPqI2FB0PM2IiH2SHgVWUUCRzLZtARyNpMWjDi8AdhQVy0RJWgV8Hzg/It4pOp4O8TSw\nWNIiSccAFwH3FxxTR6kMoN4GbI+InxUdz0RImp3N2pPUS5pUUMg9qFNnAd0LLCHNQtkFXJbtWVAW\nkl4B3gf8q/LUljLNZKpXSbbYqMYn6Rzg58A04Pa8lW2nCkl3AWeSKlH+A7g2Im4rNKgGSFoBPA48\nT/r9Bbg6IjYVF1VjJH0U+A3pZ6gLuCciflxILJ2YAMzMrEO7gMzMzAnAzKxjOQGYmXUoJwAzsw7l\nBGBm1qGcAMzMOpQTgJlZh3ICMDPrUP8HJ1/ZaV8B/OIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86bce1d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_placeholders():\n",
    "    x = tf.placeholder(dtype=tf.float32, name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, name='y')\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_hidden_layer_size():\n",
    "    return tf.constant(value=10, name='n_hidden')\n",
    "\n",
    "def get_variables(reuse):\n",
    "    n_hidden = tf.get_default_graph().get_tensor_by_name('n_hidden:0')\n",
    "    \n",
    "    with tf.variable_scope(\"params\", reuse=reuse) as scope:\n",
    "        w1 = tf.get_variable(initializer=tf.random_normal(shape=[1,n_hidden], stddev=.2), name='w1')\n",
    "        b1 = tf.get_variable(initializer=tf.random_normal(shape=[n_hidden], stddev=.2), name='b1')\n",
    "        w2 = tf.get_variable(initializer=tf.random_normal(shape=[n_hidden, 1], stddev=.2), name='w2')\n",
    "    \n",
    "    return w1, b1, w2\n",
    "\n",
    "def compute_forward_pass():\n",
    "    x = tf.get_default_graph().get_tensor_by_name('x:0')\n",
    "    n_hidden = tf.get_default_graph().get_tensor_by_name('n_hidden:0')\n",
    "    \n",
    "    w1, b1, w2 = get_variables(reuse=True)\n",
    "    \n",
    "    hidden_activations1 = tf.tanh(tf.matmul(x, w1) + b1)\n",
    "    \n",
    "    return tf.matmul(hidden_activations1, w2)\n",
    "\n",
    "def compute_l2_regularization():\n",
    "    w1, _, w2 = get_variables(reuse=True)\n",
    "    \n",
    "    return tf.reduce_sum(tf.add(tf.square(w1), tf.square(w2)))\n",
    "\n",
    "def create_graph():\n",
    "    graph_1 = tf.Graph()\n",
    "    \n",
    "    with graph_1.as_default():\n",
    "        x, y = create_placeholders()\n",
    "        \n",
    "        n_hidden = get_hidden_layer_size()\n",
    "        \n",
    "        w1, b1, w2 = get_variables(reuse=False)\n",
    "    \n",
    "        l2 = compute_l2_regularization()\n",
    "        \n",
    "    return graph_1\n",
    "\n",
    "def train_and_predict(x_train, y_train, minibatch_size):\n",
    "    \n",
    "    x = tf.get_default_graph().get_tensor_by_name('x:0')\n",
    "    y = tf.get_default_graph().get_tensor_by_name('y:0')\n",
    "        \n",
    "    forward_pass = compute_forward_pass()\n",
    "\n",
    "    mse = tf.square(tf.sub(tf.get_default_graph().get_tensor_by_name('y:0'), forward_pass))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.add(mse, 0.001 * compute_l2_regularization()))\n",
    "\n",
    "    train_op = tf.train.AdagradOptimizer(0.8).minimize(loss)\n",
    "\n",
    "    with tf.Session(graph=tf.get_default_graph()) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        n_minibatch = np.int(np.ceil(x_train.shape[0]/np.float(minibatch_size)))\n",
    "        print('Nr of minibatches: %d' % n_minibatch)\n",
    "    \n",
    "        for epoch_ix in range(3000):\n",
    "            epoch_loss = 0\n",
    "            for minibatch_ix in range(n_minibatch):\n",
    "                _, output_loss = session.run([train_op, loss], feed_dict={x: np.matrix(x_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]).T, y: y_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]})\n",
    "                epoch_loss += output_loss\n",
    "\n",
    "            if (epoch_ix%300) == 0:\n",
    "                print(epoch_loss, compute_l2_regularization().eval())\n",
    "        \n",
    "        predictions = session.run(compute_forward_pass(), feed_dict={x: np.matrix(x_train).T})\n",
    "        \n",
    "#         these lines are not necessary for this example. Im adding them for the next section\n",
    "        w1, b1, w2 = get_variables(reuse=True)\n",
    "        print(w1.eval())\n",
    "        print(b1.eval())\n",
    "        print(w2.eval())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "graph_1 = create_graph()\n",
    "\n",
    "with graph_1.as_default():\n",
    "    predictions = train_and_predict(x_train, y_train, minibatch_size)\n",
    "\n",
    "plt.plot(x_train, y_train, color='blue')\n",
    "plt.plot(x_train, y_sin, color='green')\n",
    "plt.plot(x_train, np.array(predictions).reshape((-1,)), color='red')\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Sharing states between sessions (saving and restoring sessions)\n",
    "The state of the graph is evaluated within a session. At the beginning of the session the first thing i do is run the variables initializer.\n",
    "\n",
    "Note that in the previous example i ran the train and predict steps in the same function (more importantly, in the same session). If i were to split the train and the predict steps, creating a new session for each purpose, i would have to save the graph's state after training and restore it when predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07670533  0.07616123 -0.10999765  0.03857148 -0.50601977 -0.13018982\n",
      "  -0.35415015 -0.02750931 -0.28422058  0.23983705]]\n",
      "[-0.1600427   0.00149916  0.0185432   0.01783235 -0.06350122 -0.14185522\n",
      " -0.09122319  0.04929993  0.28946036  0.06398918]\n",
      "[[ 0.02795484]\n",
      " [ 0.17125344]\n",
      " [ 0.1519064 ]\n",
      " [ 0.41733679]\n",
      " [-0.20804989]\n",
      " [ 0.09852105]\n",
      " [ 0.0566378 ]\n",
      " [-0.29851791]\n",
      " [ 0.08515929]\n",
      " [-0.26951388]]\n"
     ]
    }
   ],
   "source": [
    "# if i create a new session (even with the same graph), i will have to reinitialize the variables.\n",
    "# Losing any previous state.\n",
    "# Compare the values of w1, b1, and w2 with the ones of the previous example (after training)\n",
    "with graph_1.as_default():\n",
    "    with tf.Session(graph=tf.get_default_graph()) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        w1, b1, w2 = get_variables(reuse=True)\n",
    "        \n",
    "        print(w1.eval())\n",
    "        print(b1.eval())\n",
    "        print(w2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of minibatches: 13\n",
      "6.32577810064 4.26893\n",
      "1.41938809305 45.5545\n",
      "1.40012863278 45.6117\n",
      "1.39172104001 45.496\n",
      "1.38649858534 45.4001\n",
      "1.38281182945 45.3246\n",
      "1.38001770526 45.2635\n",
      "1.37780030817 45.2127\n",
      "1.37598226219 45.1698\n",
      "1.37445455045 45.1327\n",
      "[[  1.40129846e-45  -4.20389539e-45  -3.36311631e-44   2.80259693e-45\n",
      "    9.74285483e-01   3.50324616e-44   3.78350585e-44   8.46557379e-01\n",
      "   -7.68155277e-01   8.40779079e-45]]\n",
      "[ -1.33123354e-43  -1.12103877e-43   3.22298647e-44   1.30320757e-43\n",
      "   3.54304239e-02  -2.66246708e-44   4.06376555e-44  -2.17147660e+00\n",
      "  -2.16765451e+00   1.03696086e-43]\n",
      "[[ -2.80259693e-45]\n",
      " [  2.80259693e-45]\n",
      " [  8.40779079e-45]\n",
      " [  7.00649232e-45]\n",
      " [  1.16749489e+00]\n",
      " [ -9.80908925e-45]\n",
      " [ -3.22298647e-44]\n",
      " [ -6.77109182e-01]\n",
      " [  6.57699168e-01]\n",
      " [  1.40129846e-45]]\n",
      "Session saved\n",
      "Session restored\n",
      "[[  1.40129846e-45  -4.20389539e-45  -3.36311631e-44   2.80259693e-45\n",
      "    9.74285483e-01   3.50324616e-44   3.78350585e-44   8.46557379e-01\n",
      "   -7.68155277e-01   8.40779079e-45]]\n",
      "[ -1.33123354e-43  -1.12103877e-43   3.22298647e-44   1.30320757e-43\n",
      "   3.54304239e-02  -2.66246708e-44   4.06376555e-44  -2.17147660e+00\n",
      "  -2.16765451e+00   1.03696086e-43]\n",
      "[[ -2.80259693e-45]\n",
      " [  2.80259693e-45]\n",
      " [  8.40779079e-45]\n",
      " [  7.00649232e-45]\n",
      " [  1.16749489e+00]\n",
      " [ -9.80908925e-45]\n",
      " [ -3.22298647e-44]\n",
      " [ -6.77109182e-01]\n",
      " [  6.57699168e-01]\n",
      " [  1.40129846e-45]]\n",
      "WARNING:tensorflow:From <ipython-input-383-58ef21287d9e>:74 in predict.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "['params/w1:0', 'params/b1:0', 'params/w2:0', 'params/w1/Adagrad:0', 'params/b1/Adagrad:0', 'params/w2/Adagrad:0']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdcVtUfx9+XjTgYAqKCW8SJijvNPXNPMvdMU7M0LcvS\nMssyR2XulfPnyD1ya7n3YGsqCC5ciMo8vz8Olw2CICic9+v1vC7Pfc699zyI93O/3/MdmhAChUKh\nUOQ+DLJ7AgqFQqHIHpQAKBQKRS5FCYBCoVDkUpQAKBQKRS5FCYBCoVDkUpQAKBQKRS5FCYBCoVDk\nUpQAKBQKRS5FCYBCoVDkUoyyewKpUbBgQVG8ePHsnoZCoVC8NZw5c+a+EMI2LWPfaAEoXrw4p0+f\nzu5pKBQKxVuDpmk30jpWuYAUCoUil6IEQKFQKHIpSgAUCoUil6IEQKFQKHIpSgAUCoUil6IEQKFQ\nKHIpSgAUCoUil6IEQKFQZBhvb9i1K7tnoUgvb3QimEKheDsYMQLOn4e7d7N7Jor0oARAoVBkiOBg\n2L8foqIgIgKMjbN7Roq0olxACoUiQ2zZIm/+APfuZe9cFOlDCYBCocgQGzbE/axcQG8XSgAUCsUr\n8/gx/P031K4t39+5k73zUaQPJQAKheKV2bZN+v2HD5fvlQC8XSgBUCgUr8z69VCkCLRrJ98rF9Db\nhRIAhULxSjx9KmP/O3WCfPnA3FxZAG8bSgAUCsUrsWMHvHgBXbqApoGdnRKAtw0lAAqFIt0IAfPm\ngb091Ksn99nbKwF421CJYAqFIt0sWiSTv377DQwN5T57e/D3z955KdKHsgAUCkW6uHkTPvkEGjaE\nDz+M269cQG8fSgAUCkWaEQIGDoToaFi8GAzi3UHs7WUUUHR0+s7355/QoAEEBGT+fBWpowRAoVCk\nmUWLYM8emDYNSpRI+Jm9vSwJ8fBh2s517Rq0aAG9e8ORI3DwYKZPV/ESlAAoFIo0M3cuuLnB0KFJ\nP7Ozk9u0uIE8PaFiRTh+HGbOlFFE165l7lwVL0cJgEKhSBNCgJcX1K2b0PWjY28vt2kRgL174flz\nOHkSRo2SyWRKALIeJQAKhSJN3LoFoaFQrlzyn6dHADw9wdISnJ3l+5IllQBkB0oAFApFmvDyktuX\nCUBaykF4eICLi3T9gBKA7EIJgEKhSBPe3nKrP7UnxspK5gSk1QIoXz7ufcmS0sJ48SLj81SkHSUA\nCoUiTXh5yZo/Dg7Jf25gkLZcgOBgaSW4uMTtK1lSbv/7L3PmqkgbSgAUCkWa8PKS7h/dbZMcei5A\nanh6ym1iCwCUGyiryRQB0DRtsaZpdzVNu5zC55qmabM1TfPTNO2ipmnVMuO6CoUi69AFIDXSYgF4\neMhtchaAEoCsJbMsgKVAy1Q+bwWUiXkNBv7IpOsqFIoMsHp12hZtnz6Vmbop+f910lIQztMT8uQB\nJ6e4fXZ2ct+rCMCVKxAYmP7jFJlUDE4IcVjTtOKpDGkPLBdCCOC4pmmWmqY5CCGCMuP6CoUi/Tx4\nAO+/D199BZMnpz7Wx0duX2YB6AIQEvaUhy8e8OD5A56GP8XYwBgTQxPyGOfholcRypXLmyCXQNNe\nLRIoKEi2o2zbFlatSt+xiqyrBloEiF8nMCBmXxIB0DRtMNJKwCn+I4JCochUbt+W28vJOm4TkloI\n6M3HN9n/335O3jrJ7vwevBjhQf4f7qV8stpgEmVN9fnFqe5QnVpFalGraC1KlqrAtaupLDAkw/jx\n0jpJy3dQJOWNKwcthJgPzAdwc3MT2TwdhSJHEBAARYsm3Ke7atJy8/T2llE+pUuDEIKTt06y6tIq\ntvtu5+rDqwAUMC2ArXEF8GrPmAGlKedYEGtza/Ka5CUyOpLwqHDuPg5h8JgAXJvfpIC5H+s91rPg\n7AIA8lYpygvastO3HU1LNsHY0DjVOZ04AcuXy8gkX19ZhC65DGVFymSVANwCHOO9LxqzT6FQvGY8\nPaFCBThwAN59N26/LgBXr8qyDObmKZ/DywscXe7y4/G5LLuwjGsPr2FqaEqzUs0YUXMEjUs0poJd\nBfb8bUDLz6HDOKiXTKjHqVPAP/D5p9ChgxQTvwd+HLl5hFm7tnGxwjJar/qDQnkL0d+1PwOrDaSE\nVYkk54mOhpEjZUjqmDHw6aeyF0GxYnFj9uyRhem6dXu131tuIKv0cgvQOyYaqDbwWPn/FYqs4cKF\nuDo+8dEFIDo66Wfx8bznyZ48A/Hv7MTXB7+mhGUJlrRfwp0xd9jqvpVRtUdRyb4SBppBbEG4lBaW\nE0cAaZpGGZsy9K/an6lVNsK0YH5w3YRbYTd++PcHSs4uSae1nTgXdC7Bef78U9YR+uEHqF5d7tMT\n1XQmTJBrHGfPvuQXlIvJrDDQ1cAxwFnTtABN0wZomjZU0zS9ZuAO4BrgBywAhmXGdRUKxcvx85Pb\noESPXPFv0sm5gW48ukHfTX2pMKcCD4usomJkXzyGebC39176uvalgFmBJMe8rB6QpycYG0OpUkk/\nK1kSiDSj6NP2bHXfyo2PbzCh/gT2/7efavOr8d6q9zh/+zxCwJdfQq1a8MEHcZFJ8QUgMhIuXZLl\nqfv2hfDwuM+ESPg+N5MpAiCEcBdCOAghjIUQRYUQi4QQc4UQc2M+F0KI4UKIUkKISkKI05lxXYVC\n8XJSEoA7d8DWFkxMEgrAk7An9FjyKWV/Lcuay2sYWOFTmHGTj4rPxcXWhdSwtY07d3J4eEDZsmCU\njPO5eHG51SOBiuYvyneNv+PGxzf4rtF3HAs4RrV51ej252ACHt5l8GDp87e3h/z5EwqAj48sK9Gj\nhxSCb7+V+z09oUYNqFIl1a+Ra3jjFoEVCkXm4usrt4lj5e/ckWWYHRykAAgh2OC5gVE7RxEYEoSF\nT3+OfPc1d3wcWfDs5SGgIJ/ubWxStwCqVk3+MzMzOZ+rVxPuL2BWgAkNJjC85nAmH5rMrOO/woi1\n3LD/jmgxHAPNAGfnhAJw4YLcfv45mJrC1KnyqX/27Lh6Q6GhYGHx8u+Uk1Fr5grFW8CJE/Drr692\nbGoWgL29bMxy4VoQbVe3peu6rpgLO1h4jNDVCxnZx5GLF+X4cuWQCwbBwVJVjh+XK8v6659/wMOD\n8lZBPLid1Mfy/Ll8undJxYhILRfA0sySX1r8QnO/y5jeq8Pk0yNpuLQhvsG+lC2bUADOn5eWTbly\nsuGMvb3sYta4Mfz0kxyjWlAqC0CheCuYN0+GPA4aJJ+U08qTJ3G+/uTWAMqVg2jnv7hVdBDB10KZ\n3nw6ARtG8vs9I5bMuMvq0Sfg+HG2G1+hYENf+XgeFpbqNQ8D0X4aFHOUd/QyZaBqVfzzVcc4ujLl\ny6f8BUqWlM1iUkIIOLfHmc5Nd9Ks/TJG7x5N5bmVaVx2Gv4rPyI0VMPCQgpAhQpSBExMYMcOqVmd\nO8OhQ/JcaclszukoAVAo3gKCguSCprd3+vzX+tN/uXLyBhgVJUs2CwG3g59x3mkklyIXwaNqLG20\nlO4v7rN06Th8jbbjNNqb94GISCP8zcuilSkDrVvLhAIbG7C2lvUb9OpwYWHw8CELf3rIi/+C+Ojd\n/+Tj/IYNsGABZYEnGBP+Ux3waQpNm0LNmnJCMcQvC52c0Hl7S8ulUUONvq59aV6qOYO3Dma770jo\nvp8zVxbToKYV589DmzZxx1WpEvd7c4wJSPf3T3r+3IYSAIXiLUDP2r1y5dUEoEEDGep5/750h1z0\nv0bYB524bHSB7837km+BGe1XvAvPHuKOCYHOjWHAAKJr1eGzldVwqZ6HwYPTds2L/8JSHxi2NCYx\nSwi4cYNfep7B9NxxhkXvh6+/hokT5WQ6dIBOnaBxY0qWlLek69eTX3PQn971fIbC+Qqz1X0rYzfO\nZHrUZ3TeU5Vlpmu5e7cWrq7Jz69IEblVAoBc+HlTX9WrVxcKhUIIe3shQIjPP0/fcVOmyOOWL5fb\nc+eE2Om7UxScbCl6tckjbhUpIQSI55iKM2V7iN0f/iUsCBGXL7/6XP/8U17r4MG4fc+eCWFhIcSQ\nITE77t8XYs0aIbp1kx+AEA4Owv+DccIZT7FtW/Ln7tFDiMKFhYiOTrg/NFQIipwQlt8UF0aTTARV\nliW4fmJsbYUYPPjVv+ObDHBapPEeqxaBFYo3nMjIOD9+emve+PpC4cKyhAMIFp6Yxt8fteLi9FCW\nb39GPmMLmDOHNlWD+MxxNfPudMCqaN4EtfrTS6dOsjzDkiVx+3bulFE3XbvG7LCxge7dYe1auHdP\nuonc3Ciy+me8cMF5eBPYskX6rGIQQloA776btCdBnjzgZFiTJn6ncaIedOzDhpDPiIqOIjkcHZUF\nACoKSKF447l7V978NE26gNKDn5+8+dsWDKNX5eZ89tk4ftkNBkXr0IodXN14ET78kGKuVly8KBdg\nW7VKvenLy8iTR97b16+XhdpA/lywYMJSFLGYm0vV2LIFLSCA+SWmkjfQB9q3l6u0c+dCWBi+vnIt\nJNlzIIfe8LKhusdu8nkO49czP9FhbQeeRTxLMlYJgEQJgELxhqP7/6tWlWuqoaFpP9bPD5rk34/W\nzI7lF/cSmtee6H172Tj8ELtohX0heaevWFE+iD95Ai1T6+yRRvr2lfNct06Gf27dKu/xySWAJaBQ\nIR4OGY9jxDUezl0rVePDD6FUKe5PnI0Zz2nYMPlD9VyAi+eNaRL2O7+1+o0dvjtosrwJwc+CE4wt\nWlSFgYISAIXijcLTMy6JSUcP32zaVG71ejovI+TWEybcG8SX25tg/OgJvV368Xv7QAwaN4lN1NIz\ndytWlFsjI2jSJGPfAaBuXRn9uXQp7N4tLYFY989LaNkSIjFms2k3OHZMVnUrVYq6a0fhZ1CWsv8u\nSeAa0nF2hpAQKQKurjC85nDWdV3HuaBz1FtcjxuPbsSOdXSER4/iLJTcihIAheINYtgw6Ncv4b7E\nApAmN9C+fRhXc2FY1EJ+q2nAmb+XcUZbTOBt+V/+zh3phtefyCtUkNu6daFA0hI/6UbTpBVw+LBM\nvLKxIcUn98RUriyzk3fujDlR06ZEHzhEt4L7eW5ZGG1Afzlox44Ex8WP6dcjpTq5dOLvXn9z++lt\n6i2uh0+w7Gyjl8bO7VaAEgCF4g3Cy0u6bUS8Thi6ANSrJ8sapLoQHBEB48cjmjXDX9ynTl9TDCdt\np2PN3jg4xJ3r7t24wm0gF4obN5aJZplF797y/n30KHTsmAb3TwyaJq2Av/+WC+AgXUnr7jfi1K/H\n5YJCRIQM9H/vvdhaF/EFIH4IaINiDTjc7zDhUeE0XNoQz3ueKhcgBiUACsUbQkiI9PeHhMh2jTq3\nb8flXLm4pGIB3LgB77wDP/7I2jr5qDnIhJP799CnnnTqxxcAvQyEjqbBvn2yumZmUbQoNGsmf06r\n+0enVSvpojl5UtbwmTABKlWCbt01mc57+bI0LQ4flubLF19Q1OY55ubSgonfFwCgsn1lDvY9SLSI\npuGyhjzLK1VUCYBCoXgj0Iu2QcJ6OEFBUKiQ/LlixRQsgMOHwc2NaG8vRvUvzKD3oqn3YDeFwuuT\nN68cUriwPJcQSQXgdTFhAnTpAo0ape+4Zs1kgvDOnbBwoaxAMXVqvKRhExPZCcbHB9zdYepUDKpU\nop/jXqpXTz6KqbxteQ71PYSRgRG99jYCWw/lAsruCSgUCkl8Afjvv7ifg4Lk0ztIAQgIkE/Hscyd\nC02aEGllSZuRBVlU6jE7e+4kxKNuTPy/xMFBPk0/fCgFQG/e8jpp0EC6b4xT7+6YBEtL2ex90yaY\nNAnq15dVKJJQqBAsWybNFwMDfvdpxmarvvJLJoNzQWcO9T2EsaExBn2bcjnQL93fKSehBECheENI\niwDoi7UeHkB0NPc+GA0ffkh4k0Y0GmbOYbPb7Oy5k3ec3sHXV0bi6Ojn+O8/6WbKCgsgI7RqJa2d\nu3fhxx9fkpvQuDFcvAgTJpB30wqplIkWiXVKW5dmb++9GBhFsNW6SYLooNyGEgCF4g3B11fWqSlY\nMM4FJIRcA4jvAgLwOB9OWPde2K6cySyDD6nX5hknQrz4q/tf1C9Wn9BQKRyJLQCQlTLhzRcAPR+h\nQweoUycNB5iZwXffydrZ1tZykXjAAKl2iShvW553rv9NuPaEpn825c7TFBoY5HCUACgUbwj6E3uJ\nEnEWwKNHssimfvN2cgJ7i6fU/bEdputXMV77jo+7X+fMg6Os7LSS5qWaA3FNVd5mAahWTfZA+O23\ndB5YvTqcPg1ffCETEVxdZT5BIioVrIrZhh3cenKL1qtaExKWVChyOkoAFIo3hOQEQI/a0W/eBs+e\nsktrhfPNPQxgAXsm+YDzTtpp8+haIS7UxtNTbuOHRiYWgKxYA8gImgYffRRXvTNdmJrClCmyeFB0\ntIyO+vrruLhSZJTSM+86LGuzjgu3L9D5f50Jj8pdzYKVACgUbwCPHslSzWXKyJr4N27IZFe9DISD\nAzJttVUrKoUew53VHB/mz9no5Viem0Qer4QB/OfPy7j7+CWV8+aVRdr0TOM33QLIFN55R/4yevaE\nyZPlWkFM6I+eC1DBpA0L2i5gz7U99Nvcj2gRnY0TzlqUACgUbwD6AnDZstICiIiQjVFiLYB88ubP\nsWNcGLcKj14heNhNZkDVAdQO/ypJeYgLF2TOgKlpwv0ODnEu8VwhACATA5Yvl6+zZ2Wa8NatCZLB\n+lXtx/eNv2fVpVVMPDAxweHBwVI/fvstriprTkEJgELxBqALgO4CArkQHBQEpryg1Oh20o+9ahX3\nB1riVXoILUq14I82f1ChvIaXV8LyOBcukGxDFN0NlD9/+lpL5gh69ZIC4OQE7dpRacU4DImMzQUY\n/854BlYdyJQjU1h6fmnsYdu3w6pVMGKEzKVo3VqmH+QElAAoFG8APj7S512ypHyBXAe4cyuStQbv\nY3TkACxdimejSnRb142KdhVZ13UdxobGlC8vF4qvX5fH3b8PgYHJdw7TBeBN9/+/NsqWlUI6dCgF\n5k1jP4155BEIgKZpzGkzhyYlmjB462AOXj8ISDE1M4Nz52DsWBlkVLeuLHHxtqMEQKF4A/D1lQ+m\nZmZya2AA/10TtN46lPbRf8HMmQR3akXb1W0xMzJji/sW8pnmA4ht3qK7gXQff2oCkGvcP8lhZgZ/\n/AErVuCmnWHQnKpw8CAAxobGrO+2ntLWpem0thO+wb5cuCDDb11dZTbyyZMyyrRxY9nH5m1GCYBC\n8QYQP2nL2FguUFbbNJFGVxextOgEwj/6kC7ruuD/xJ+/uv+FUwGn2GNdXORWCUA66dmTfhVO8djA\nSpZanT4dhMDSzJLt72/HQDOg/Zr2nPN4QuXKcYeVKiWf/qtXlzWOjhzJvq+QUZQAKBTZjBAkydod\nar6MDpe/Y12BgWyr+S2jdo7i4PWDLGq3iDqOCbOiChSQvmk99PPCBXmj12v9x6dwYblVAiCJLFue\nTkVPymyzMWNkK7OnTylhVYJ1XdfhE+zDg4Y9qVQ5YWRQwYKyTIUQcOZMNk0+E1ACoFBkM8HBMgw0\nVgAOH2aMzyCOmDThQzGHByUWMffMXD6r+xkfVE6+XGf58gktgOSe/kGtASSmaFHwCsxP1Jp1MG2a\n9OnUqQNXr9KoRCOGOM0C522cyf9VkmNtbKSrLjg4mRO/JWSKAGia1lLTNG9N0/w0TRufzOd9NU27\np2na+ZjXwMy4rkKRE4gfAYSfH3TsyCPrkrQLX0dw/jMczjec5qWa832T71M8h4uLFICwMLlNSQCU\nBZCQ+vVlesWXX2lyhXfXLrmC7uYGu3bheHsYnBnIipvfs95jfYJjDQzAyiph6e63jQwLgKZphsDv\nQCugPOCuaVr5ZIauFUK4xrwWZvS6CkVOQRcA58Ih0K4daBr/fr6dR3nDoFtnrAyLsLrzagwNDFM8\nR/nysgfv3r0yhyAlAXB2hhkzoFu31/BF3kK6dIEhQ+CHH2SoJ82ayTISTk7QujXF1kzD8eJv1C5a\nm36b++F5zzPB8TY2ygKoCfgJIa4JIcKBNUD7TDivQvHWExoqKxGkhq8vGBoISn3bV8aDrluHdS0n\n6NoNzB/yjctfWJtbp3oOPRJo9Wq5TUkANA0+/ljeuBSS2bNl2eoBA+S9nxIl5Cpv1664XxjPioi+\nrG+znDzGeej0v04JagZZWysBKALE76sTELMvMZ01Tbuoadp6TdMcM+G6CsUbTVgYFC8O8+enPs7X\nF36w/AGDTRulH7pRI9bcmwDFjsDW+dQrlcLdPB66AGzaJLN/y5bN+PxzCyYmssukvb1cCw4JASws\neLF0DV9oU3kncC1FWnVjU+1Z+Ab70m9zP0RMz05lAaSNrUBxIURlYA+wLKWBmqYN1jTttKZpp+/d\nu5dF01MoMh8/P5mUdfFiymOEAIt/dvPJgwnQoweMHs0mr03MufAThueGwsUPYktBp0bBgvIVGipj\n1tPaf1chsbWFlStl+Y0lS+S+Kx4aU8V4jn6+Da5do06nkawoOJgNnhuYcXwGIAUgV68BALeA+E/0\nRWP2xSKECBZChMW8XQhUT+lkQoj5Qgg3IYSbbXJxbArFW4K3t9ym1nbQY7c/0269z8MiFWHhQvwe\nXqXPpj64FXajzNWZGBgkH86ZHLoVkJL7R5E69erJDN+ZM2VZjdiief1ay+wvKyu6j1rAHwGujNs7\njuMBx5ULCDgFlNE0rYSmaSZAD2BL/AGapjnEe9sOSLiSolDkQHQBuHUrhQEREVgMdMeEcLQN63lh\nakjXdV0x1AxZ13UdpYqZYm8frw/uS1ACkHE+/VSW4Ni0SQqAhYVM/MLZGU6cQGvenKELz7N0lzk9\nV3fF3DqYp09lq823kQwLgBAiEvgI2I28sf9PCHFF07TJmqa1ixk2UtO0K5qmXQBGAn0zel2F4k3n\nZRaA+GoixW/9yx9V5mFdqyxj/h7D+dvnWdZhGcUtizNuHPz0U9qvp2cEKwF4ddq3l2vAv/wiBaBS\nJRnuCchGxVu2wLhx9DwawpI5t/jnRXfQot9eK0AI8ca+qlevLhSKt5XatYWQXn4hXrxI9OHOnUKA\nmM9AsWyZEOuvrBd8g/hk1yevfL3AQCFGjxYiLCxj887tzJol/82MjIQYMiSFQatWiQhTY3G9AMK1\nykhx+XKWTjFVgNMijfdYlQmsULwGhAAvL+lCgLi6/gDcuQO9exNoXZFxprNwbfQfA7YMoGaRmkxt\nOvWVr+ngIJ9cTUwyNvfcTr9+srxGZGQq1pS7O4b/HMVcM+ffK7MJWvJtls4xs1ACoFC8Bu7dk+Ud\nGjSQ72PdQEJA//6IkBB6sIaG7xkzaHcPANZ0XoOJobp7Zzf58sHgwfLn1NxpmpsbfivPccbOlKbT\nJxL26ccJmzK8BSgBUCheA7r/v0kTuY0VgDlzYMcOvAf8xJEHFaDRRE7eOsnCdgspYVUiW+aqSMqE\nCfD771C7durjilZ0pon2N3+4aZj+MgvRqlWqcaGPH8OzZ5k82QygBECheA0kFoBbt5BFesaMgdat\n+enZcMwr7GPT/R8ZVG0QXcp3yba5KpJSoAAMGxZvATgFrK0h4lYDtnSYwsC2EH3wgKwjpMeQxuPZ\nM6hWTWYcvykoAVAoXgNeXjIjt1IluQ4QdCNcNpbNlw8WL2bbwfvQsRfOBZ2Z0WJGdk9X8YpYWMg1\nl0pPxvFfl8Y0HmBI5PNQWVF01aoEY6dMkW0+9+6VnsA3ASUACsVrwNtblmMwNJQlh2vv+RbOn4eF\nC3lgbMfd2gMINwpmTec1WJhYZPd0Fa+IpsVkAwcbsLzDci6XsKDNJ4WIrlZNCv7IkRAejpeXDOm1\nt5fZ4W9KT2ElAArFa8DbW+YOATTJf4oOXlOhb19o146pe+aB81b6O/5IlUIqaP9tx9pauv2L5C/C\nwrYL+fvZRb78sg6MHg2//opo1IiJAwOxsIC1a+Ux//yTvXPWUQKgUGQy4eHS1Hd2Bp4/5wufPtwx\nLAwzZ+J134tZ3p/A1WaMbzQyu6eqyATiF4Tr6NKRQdUG8cOJ6ewf8R6sWUPkmQv8+m9VlvXeR4MG\ncvy//2bvnHWUACgUmczVqzIa0NkZ+Oorijz2ZIBYxHNzc3pu7IlhVB7Mdi+leDH13y8nkLgi6IwW\nMyhjU4Y+m/pwr3Vzmlue4qlZQdr+2gztu295p260sgAUipyKHgFUPewo/PILV+oPZXd0Mz7b8TVn\ng87i7LOACo6FXxphong7SCwAFiYWrOi4gttPb9N58XAO3nHBa9lJtJ49YeJEZni15LHvHe7ezb45\n66g/QYUik/H2BlNe4DytPzg5cX3YNHA6wu8XfqS/a3+C/+kYW7hN8fajrwHEj+ypUaQGExtM5Mij\n1Vi/u4oWnSxg+XJYsACnG0e4QBV85uzNvknHoARAochkvL3hJ4tJGPp6w4IF5CshoGNv7ExKMKnu\nTAICUAKQg7Cxkes+oaEJ93cr/Dn41+FZo2EEht6UIUMDBxJ17BQPNBvqTmoOn3+eraVElQAoFJmM\nOH2GYaE/Qf/+0KwZc6+PhgI3cTddTsDVfABUqJDNk1RkGnp7zcQVQRcvNMJg858YGkfRd1NfooXs\nDWpSrSIjap1ii91A2Yy4Xr1siwtVAqBQZCbh4Xzq0Z+QPHYwfTqbvTaz2msxBsfGYXq3Hh4ecpiy\nAHIO1jHtmuNXgAgLg8WLoX39UsxsOYMD1w/w28nfYj+v8W4euj2cT9iqDTJkrGpV2Ts0izPElAAo\nFJnI069/omLURQ52n8td43AGbR2EayFXHK9+Q0CArAZhZiZ7BStyBslZABs3yoSvDz+EAVUH8F7Z\n9xi3dxye92QvrHr1ICICThTpBBcvElq5DgwZAm3aQGBgls1dCYBCkVl4e2M+/Vv+R1es+rRlyLYh\nPAl7woqOK3AsbBIrAOXKpb3Ll+LNJzkBmDtXdhJr0gQ0TWNB2wVYGFvQe1NvIqIiqFtXjps3D1oP\nKkK+438z1WE2HDwomzqvWpUl1oASAIUiM4iOhsGDCTc0Z7TBbHzM/2ST1ya+a/wdFewqUKQIsQKg\n3D85i8RvQNZQAAAgAElEQVQC8PgxHD4MvXrFFZMrlLcQ896bx+nA03x/5HtsbOTfwapVcOYMVHE1\nYPLDEYhz52UCybhxWVI2VAmAQpEKDx/CokVpeBhbtAgOH2ZOiZ+xqhXBmP0jqO9Un9G1RwOyHtDN\nm3DjhhKAnEbiNYDTp+VWf8rX6Vy+Mx9U/oDvjnzHmcAzzJkDS5bIv4k+feDFCwi2KSvrRBw6FNdN\n6DWiBEChSIWlS2HgQGIXb5MlKAjGjkU0bMQ3/n153LA/UdFRLO2wFEMD6espWlT6fEEJQE7DxATy\n5o2zAE6elFs3t6RjZ7ecjZ2FHX029aFWvRf07SvXhJyc5Oc3byL9gyVLZsXUlQAoFKnhKdfsuHIl\nlUEffwwvXuA7Zh5PXeYRYLqXn5v/TEmruP/ERYrEDVchoDmP+NnAp05BmTJgZZV0nJW5FYvaLeLK\nvSt8feDr2P2OjnLr758Fk42HEgCFIhW8vOT28uUUBuzYAf/7H3z5Jev9DaDZWN4p1Jwh1YckGFa0\nqNyamGTZw50iC7G2TmgB1KiR8tiWpVsyuNpgfjr6E0f9jwJKABSKNxJdAJK1AEJDZdsoFxeix45h\n9o1+aMKYld0XomlagqG6ADg7g5HR652zIuuxsZFrAIGBsvtbzZqpj/+5+c8UsyxGn019CA0Pxc5O\nPhzcvJk189XJ8QLQooVMtlMo0ktwsGzuDikIwDffyBW8+fOZdfYP7pgdoWLALJwsHZMMLVRIVgJQ\n/v+cie4COnVKvk/NAgDIZ5qPJe2X4PfAj8/3fY6BgXxIUBZAJhISAnv2wJEj2T0TxduIXtWzalXw\n85PZnbFcuAAzZsCgQXiXs+WLfV+AVzs6l+qd7LmMjWU74H79Xv+8FVmP7gI6dUqu4Vat+vJjGhZv\nyMiaI/n15K8cvH4QR0clAJnKpUsyfC8gILtnongb0d0/nTvL+v66IBAVJbM2ra2J+n4KfTb1wVjL\nA9vmUaeOluL5pk2TFqki52FjI0OGjx+HypXB3Dxtx01tOpXS1qXpt7kfDsVClABkJhcuyK0SAMWr\n4OUl/bLvvSffx7qB5s+HEydgxgymey/hxK0TtIz6HS20ELVqZdt0FdmIjY182Pznn5e7f+KTxzgP\nS9sv5cajG3gXG8utW/L5IqvIFQLw4EGWJNUpchheXrKxu4uLXLi9fBm4fVuW8G3aFI9mrnx14Cs6\nu3Qm9GR3XFygQIHsnrUiO9CzgcPCXr4AnJh6TvX4tM6nnDOcR1SxPQQFZf78UiJTBEDTtJaapnlr\nmuanadr4ZD431TRtbcznJzRNK54Z130ZugCAsgIU6cfLS9btMTGRcd1XriAbfb94QeRvs+mzuS/5\nTfPze+s5nDiuUbt2ds9YkV3o2cCQPgtAZ3KjyRQ1KwftB+B57XHmTewlZFgANE0zBH4HWgHlAXdN\n0xLHOgwAHgohSgMzgB8zet2XER0t1wAqVZLvs9q3pni7CQuTvX3LlZPvK1QAq1N/w5o18MUX/Hhn\nI6cDT/NHmz84vNOO4GCUAORidAsgT55Xi/QyNzbnh9pLId8tpp79NFPnlhqZYQHUBPyEENeEEOHA\nGqB9ojHtgWUxP68HmmiJA6UzEf/H/lzwCiE0NM5/qyyA3EtUVPr9qn5+8iFCF4AqZZ/zZeCHRJcp\ny+W+bZh0aBI9KvZAXOmCu7u8+bu7Z/7cFW8HugBUq/bqeR5tqtSCfz/jwONF7PTdmXmTS4XMEIAi\nQPzn64CYfcmOEUJEAo8Bm0y4dhIePn9IlblVGL93HCDLa4MSgNyMuzv0Tj46M0X0CCBdADp5TaEU\n1/D+9Dd67xyEtbk1DZ/9Ro8e8ua/e7esB6PInegCkF7/f3wKFIC8Z77BOrICA7cOJDQ89OUHZZA3\nLidR07TBwGAAJ71CUjqwMreif9X+TD82HYPSnahevSkFCyoXUG7m/Pm0h+Xp6ALg7Ax4euKyZRrL\n6cXmsGOce3iOyeX/YlgPG+rXh23b1M0/t2NtDTNnQrt2r34OTQOnwqbYXV3GsAnXsDB5O6qB3gLi\npz4WjdmX7BhN04yAAkCiDpoSIcR8IYSbEMLN1tb2lSb0baNvsXjujGHHAYRrTyhaVFkAuZnbt+Hu\n3fQd4+UlMzPzWggYOhTy5WW8Q182PfiW7i49WTq+AyVLwvbt6uavkIwaBSVKZOwcjo4Q4lOdrhW6\nZs6kXkJmCMApoIymaSU0TTMBegBbEo3ZAvSJ+bkLsF+I19fuxtzYHIs9S4nME8CYv8fg6KgEILcS\nGiozwu/dkz79tOLlJcM/WbYMDh8m6ofvedh9NMYRBbE5OZtr12DBgiwp2a7IRTg5Za23IsMCEOPT\n/wjYDXgC/xNCXNE0bbKmabpBtAiw0TTND/gESBIqmpk8eAB3z9amgdFYFpxdQHTJXcoFlEvRY6qj\nomSmZloQQgpA9WL3Zf2GevWYXDKAF5YXMdi+gLkzrBk8GBo2fG3TVuRSHB2ltfriRdZcL1PWAIQQ\nO4AdifZNjPfzCyBrbBrg4kW5/aTaN9y7vpUjDOTJs8s8e2ZJnjxZNQvFm0D8pJq7d+MW60Bahbdv\nJ23cERgIT59Cn0tj4MkTLn87gu+P9KQqfTl34T0KF5ZlHRSKzEYvCx0QAKVLv/7r5chMYD0BrGY1\nM5a2X8pTbkOL0dxKvDKhyPEkFoD4TJwIHTokPcbTExpygHInlhE55hO6e06mUN5CTHCbAcAff6iM\nX8XrQY97ySqPRY4VADs7WYK3RpEauDuOh6pL+d/5bcmOf/4cnjzJ4kkqsoT4AnDnTsLPbtyQnyfO\nEfC99IK5DCWyWCm+rhuOxz0PFrZbSKfWlvj7ZyzSQ6FIDd0CyKq+ADlSAM6fhypV4t5/Xnci3K7M\nT96DCH6WNPho1Cho0iQLJ6jIMlKzAAID5cKwXvNfp8y673HGB+8pI/jh7CwGVh1Iy9It0bS4xi4K\nxetA//tSFsArEhEha7bEF4CSxUxg0zJCou4zYueIJMdcugRnzsiIEUXOIihI9uPVtOQFABJZBleu\n0PDED2yw6EHHB79TNH9RpreYnmXzVeRuzM3B1lYJwCtjZCQFYES8+7y5OdhEuFI9ZCKrL69mvcf6\nBMf4+8vIjxT7vireWoKC5FNVwYIJBeDp0zi33+3bMTujo2HQIEIN8zPxvXz4PvBlSfsl5DfNn+Xz\nVuReHB2VC+iV0TS5ep44ibhoUbD1GY9bYTeGbhvKnafysS8yMs5NcP58Fk9W8doJCgIHB7kmFF8A\n9Kd/iCcAc+fCsWNMKjUED5cFfFTjIxqXaJyl81UosrIzWI4TgJRwdIRAf2OWdVjG0/CnDN42GCFE\nrB8YEpaPVuQMdAGwt3+JAAQEwPjxRDZpxKyWK8kfWYofmqpm0oqsx8kp7TkrGSXXCIDecLm8bXm+\nb/I9W7y3sPzC8lhTy8hIWQA5jfBw2af1ZRbAndsChg+HyEgmdLElOr8/XYyWZ0ktFoUiMdOnZ13l\nglwlAMHBMuRzVK1R1Heqz8hdIzl/Tdpa774rE8iysh2b4vWiu3aSEwA9J8TWFkqcXAtbtuAx0p1p\nd/4HR8dSy6Fu1k9YoQCMjaUrOyvIVQIA8j++oYEhSzssJVpEM+tGP9CiadtWRgFdvZr88devy+zP\n11fBSJHZ6Gs7ugA8fiwbvYC0APLmhRol7tPr1Agi3KrRzGY7pfNVggOTcHDIvnkrFFlFrhEAPcFC\nX1wpaVWSX5r/gl/0Pkwb/EaDBnJ/Sm6g33+HceNQ2cRvEYkFAOJi/gMDoXBhGB80CouIx3zubsvd\nF8EMc1gOUaZKABS5glwjALoFEN+3NrDaQOwftya8wTgM7b0wMkp5IfjYMblVAvD2kJwA6G6gW7eg\nk8k26vuvYlrRtkwP2c3khpMxf+wae4xCkdPJ1QKgaRp2xxdiFJ2HAdt7Ua58RLIWQHg4nD6d9HjF\nm01QEBgYyJt/YgF46v+QsVeHEGTnzCT3vdQpUpfP6n1GUJD0v+rjFYqcTK4RgDx5ZNeexPG1Qb4O\nvBsyj9OBp9EafpusAJw7F+c7VhbA20NQkLyRGxomFAAhYGzAKAq8uMNHXfMTYRzFtLrLMTQwJChI\nJo0ZG2fv3BWKrCDXCADI+Nr//ot7//w53L8P79p2oXeV3ly2nkKgwbEktWGOHpVbAwNlAbxN6DkA\nkFAAnq7cTM/oP1nfuAkbbU/BrpmYPSuV5BiFIqeTqwTA1RXOno2L5NFv5o6OMLvlbOxMHaFTL46d\nCUlw3NGjUKwYFC+uLIC3iaAgWREWZMSPmRk8vRGM2cdDOGdUjv51D1Lfri2cHRAbMnr7thIARe4h\nVwmAm5t8AtTdQPrW0REKmBVgYZs/weoaU86Mjj1GCCkAdeuiegu/ZoSAf/7JvPPFf5rXNLC3E7Tc\nNhzDxw/o2zESM3MrZjVZBGixBeGUBaDITeRMAfjmGzh5MsnuGjXkVl/Q1QVArxv0XqX65Ls4jpOR\ni9jgsSF2TGAg1KmjBOB1c+AA1K8Pp05l/FxRUbLKZ/ybeS+jVdS+vpZlzWpysYIfP72zGBcnW0A+\n+UdHJz1GocjJ5DwBePAAFi+Wj+yTJ8tqbzFUrixLPiQWgPg13utHTsI0uDqDtg4i4ElArP+/bl1Z\nVvjWLZUM9rrQ3TA3bmT8XHoT+Nib+Y0bjL85jNOWFRhY4184OZz3a7TGzAwsLeW179+Xfy5KABS5\nhZwnANbWsqZDjx7w9dfykdLPD5A+4EqVEgqAra3cr9OujQlhq1YRGhZG7796c/RYNObmUjyKFpXR\nQMFJe8ooMoHHj+U2ceeuVyF+DgBRUdCnD5oWTfdudygQ7YLV6Wmx/+6FCslr6sfo6wYKRU4n5wkA\nyEe6FStg9Wrw8pKrv0uWgBDUqCEFQAhZc1vPENYZOBDqlC2L8d7ZHLh+gI13fqZmTRkWWKSIHKPc\nQK+HR4/kNrY8cwZIIADTp8OhQ3zdqhTX7J5Q2Xc1RezyxI4tVEheM8ExCkUuIGcKgE6PHtIacHOD\n/v2he3fquTzg4UO4dk1aAIkFwNAQFi6E8BP9KfyoC7fKTqB4PbmeEL+ekCLzeR0CUOz2CZgwAd/G\nrvxc9QLs+YnAs1VixRxkqejbtxMWj1MocgM5WwBA3uH37YMffoC//qLHD1VowCFOn05eAADKl4cv\nJ2gEzp0PIYXZndedJ2FPks0mVmQeqQnArl3w4kXazxUUBAV4RKHRPQgvZEf92h64WrSBEyPw85N1\ngHQSu4CUAChyCzlfAEA+1o8bB8eOYZzPnAM0wuLHr3j2JCJZAQAYPx4qlraCDau4F3GDIduGYGcn\nVDLYa0RfA0gsAH5+0KoVTJmS9nMFBQqWGg9GC/CnTzdjNGtrPi+/BNAQIqkAPHkircL8+WXWuEKR\nG8gdAqDj5oZ27izbbfvy3rnvOEwDXMz+S3aoiQls2ABLJtdjUsNJrLm8hj8vL8HBQbmAXhcpWQB6\n9vYff8CzZ2k7V6Vj8+kQsY71PV1Zm/8mKzquoGwR29jPE7uAQJb8UE//itxE7hIAgLx52d1tMd1Y\niwuetPrCVS4WJ0PZstC3L4x/ZzyNSzRmxM4RWDt7KAvgNaELwJ07CUNt9XDd4GBYvjwNJzpzhn4X\nRvFvoYp0L36GLxt8SZOSTRIUeEtsAQBcvqwigBS5i9wnAMiEsHV0w5XzRDlXgPffh3794OnTZMcb\nGhiyouMK8pnk43rNLtwMCs3iGecOdBdQRETCnqj+/jKT19UVZsyI6+GcLMHB0Lkz942s6fzBNRqU\neJev3/0akCG/OskJQFiYsgAUuYsMCYCmadaapu3RNM03ZmuVwrgoTdPOx7y2ZOSamYGbm9z6GxTH\n8N/D8NVX8tGyWjU4cybZYxzyObCy00pCTL24Vv5DhMoGy3QePYJ8+eTP8d1A/v7STfPZZ+DjA9u3\np3CCqCjo2RMRFESndnl4YpGHlZ1WYmhgCMhQXmtrOTQ5AQAlAIrcRUYtgPHAPiFEGWBfzPvkeC6E\ncI15tcvgNTNMuXJgYSH/sxuZGcmM4f37ZXnQOnVk3Hgyj5lNSjahqfHXRJT/k9+OLnqla0dHQ9Wq\nMk1BkZBHj+S/DSQVAEdH6NJFbn/5JYUTTJ4Mu3ezqE91Tla8Rq88KymSv0iCIXZ2sqqr7vcHaRno\nPViVAChyExkVgPbAspiflwEdMni+LMHQUN7nnZ3j7Xz3XdkO7L33YMwYGXaSTDxin+JfwtWmjD0w\ngnNB59J97Vu3ZNvJFAyNXEtYmAzz1P9NkhMAY2MYORIOHkzm97d+PUyejHfbugwqfAwOfk1Dx+ZJ\nrmNnJ2/+RkZx+4yMZA8AUAKgyF1kVADshRAx0dPcBuxTGGemadppTdOOa5r2RojEypWwalWindbW\nMvRn7lw4ckTWf9ixI8EQJ0dD2LiSfIY2dP5fZx48f5Cu6/r4yK2+4KmQ6P7/xBaAEAnzNQYNkqGa\nP/4Y7+AzZ6B3b55Wr0zNqqdxs24Oh79MdkG3bl1i+z/HRx+rBECRm3ipAGiatlfTtMvJvNrHHyek\nUzwlx3gxIYQb8D4wU9O0Uqlcb3CMWJy+l7gzSyaiPwkmMwEYMkTWiyhUCNq0kY+dMVlIRYoAoXYM\ntV5PwJMAPtj4AdEitVXJhOgCEH+RMydx6hRseYVVHl0QixWTIbi6ADx6JNfm9YqtBQrARx/JB35P\nT2Sp1vbtiSpoQ+MOjyhgac9Aq5UgDJO9mU+dCmvWJN2v/y0oAVDkJl4qAEKIpkKIism8NgN3NE1z\nAIjZ3k3hHLditteAg0DVVK43XwjhJoRws40ftpHVlC8vS0qPGgW//ipDhy5dio0fN71Xm1ktZ7HT\nbyffHvo2zafN6RbA55/D0KHpP063ACwt42rzQMKeDTqjR8tkrZ8nhUL79ohHjxg+pCgXuM26rusI\nvSf9OekJ6dTHqjBQRW4ioy6gLUCfmJ/7AJsTD9A0zUrTNNOYnwsC9QCPDF43azAzg5kzpRvo3j2o\nUQOzuTMpaB3NrVsw1G0ovav0ZtKhSWz13pqmU+ZkAYiOlhZAUFDaE7Z09N+HLgB6RdDkBKBgQRg+\nOILOa7shzp5l+djmzIs8zpzWc6hVtBZBQWBqKq2FtFKqFFhZyZdCkVvIqAD8ADTTNM0XaBrzHk3T\n3DRNWxgzxgU4rWnaBeAA8IMQ4u0QAJ1WrWRRuebNYfRotoa34JnvLTRNY26buVR1qErPjT3xvOf5\n0lN5e8ttTnQBeXvLkgqQsPdyWkgsAKlZAAjB10FDaM0OZjToT1/+4kO3DxlQbQAQ19ZRj+xJC2PH\nyqWE9ByjULztZEgAhBDBQogmQogyMa6iBzH7TwshBsb8fFQIUUkIUSVm+2rxk9mNnR1s3gzz5uH6\n/CizD1aCtWsxNzZnU/dN5DHOQ7s17Th1+WGKDWPCw+NujDnRAjhxIu7nq1fTd2xqAmBklMg189VX\n5FmzhA21BvFp3VVUt63LzJYzYz++fTv9rhwLCyhRIn3HKBRvO7kyE/iV0TQYPJgpnc/hq5WV5abd\n3XGMsmBDtw1cf3iDmj/2YMu2yGQPv3ZNuklKlZJPylFRWTz/18zJk9L1AvK7pgd9DaBAAXnzvndP\ndufy95dJW4aGMQOnTYMpU3jW531GdN4Bz214984GTAxNYs+l+voqFGlDCcArYFKxLLUj/yHim+9k\nOErFitS79IgK1+dA6b/54tAnyR6n+/9r1ZJb/aaXUzhxAurVk9m8r2IBGBhA3rwyIkcIKQIJSnbP\nnAnjxhHZtQvN6vjxOOIhTv9uIcAr4eP+q1gACkVuRAnAK1CsGERhxMmmE+Rjr40NvPceo5f8g9Xh\nYXjk+5XZJ35NcpwuAHpz+pzkBnr+XC6T1KolLZz0WgCPHkn3j6bF3bxv344nAH/8AaNHIzp1on8X\nI47ePsmKjiuoYOOqd/wEpJstOFhZAApFWlAC8Ap06BBXm0a4VoXTpzlYbwI9WcH1U5tou68mo3d9\nzHafhEVrfHxk2QHd15yTBODcOemy0QUgvRbA48dxUTu6AAQFyd4LPe7OhmHDoG1bJg125k/PNUxp\nPIWOLh0pXRp8feOqh+rRQ8oCUChejhKAVyB/ftmc5OhRmVQUrpnS3fc7xtY/gXlRG7YcOcnG9QX4\naGm3BOUifHxkiWlLS/k+J0UCnZRdM6lZE0qWlIvdqVbtTIRuAUC88syXBGPDvqX9/lHQsSOLv2jF\npONTGVB1AJ+/8zkApUtDSIh0F4Hq6qVQpAclAK9I376yeOhnn8nCbnfvQosvqmN8/jR/FP6WVldC\nOTvrBcs+bsh/D6Q/xMdH1rrRY81zkgVw8qR01Tg4SAsgPDx9jXPiC4C9PWhE47JoDN8ykZuN+rBr\nSn8G/z2CFqVa8EebP9Bi4jVLl5bH6G4gPXpIWQAKxctRAvCKGBrKNcmAAPjwQ/nU27w5YGJC0IAv\nqcp5DMu7MvN/T7hfswIBh44QFJTQAshJAnDihHz6B/m7gPS5geK7gCwMnrPOyJ22vr8wi5Ec+uJD\nuvzVg0r2lVjXdR3GhsaxxyUWAN0CUAKgULwcJQAZoH596NZNPu0OHSqjWABatwYP4cKO0afw++lz\nSga+wL7xu0wzGEX5ok9ynAvo/n256KsLQKmYSk/pWQiOtQDu3IFGjegYuY4x/MTHNkP4+EwbbC1s\n2f7+dvKZ5ktwXPHi8vee2AJIts6TQqFIgNHLhyhS45df5I1r0KC4fTVqyMCgHbsM6LH8e3bXK0/g\nsN6MPT+biI//h1HUNAy0D3j0KGekner+fz281dFRWkjpsQAePYKK4WehVie4e5cvy21gelA16FMP\nEyNj9vbaS+F8hZMcZ2Iio7LiWwAFC8rS0QqFInWUBZBBihSBefPi3Dogb34tW8LOnXIhtEWdD9ja\nYRm1BsC1/M/R+vTmpEFtrD3+yb6JZyInT8qn8OrV5XtjY3lTTqsFEBUpcA+Zx6i1dWUo0ZEjXKpS\nF3o1x8A0lN0f7KaUdYoFZCldOqEFoBaAFYq0oQTgNdG6tXSN7Nsn35v79OKq/1xcPnjM7x+6UYQA\nPvmrPnTuHJcg8JZy9qys4583b9y+NIeChoQQ+X4v5jGUgDIN4dw57jgX5WiZxpD/Fq4e26lsXznV\nUyQWAOX/VyjShhKA10Tr1lC0qGww9ttvslBadYYwveUvfGR/GrcP6rG8zDewe7csPT1wINy8+Vrn\nFBoK48fLbWZy9678rvEpWTINFsD+/VCpEiYbVvMl33Jw7A7u5hE0Wd6EEKPrsHI7FQvUfen1S5eW\n6ykPHqgyEApFelAC8JqwtJRPxk2bwogRstKkszOMrjOaH5v+yK0S6/ikyWUifLxkh5M//4QyZWD4\n8NcmBLt2yU5aBw5k7nnjh3DqlColM3KTLXfx9Kn8zk2agIkJvouOMIUvIV8wTZc35drDa4wsuA1u\nvJuwCmgKlCkjt76+ygJQKNKDEoDXiK0tbNsmF4qNjWU7QoDP6n1G5cBfCC60nq6HPyLs5x/B15f7\nbfogFiyQd88BAzLdNeQZU606mVbHGSI5AdBDQRNYAULIPpzOzjBnDnz8MZw/T2DxupDfn4n/1cfv\ngR9b3bfSsFgjgDQJgB4KeuqUjMhSFoBCkTaUALxmNE12sAoJge7d4/bXjB5N/n9+Y7P3ZtqtaUeI\nvRV1L89nQAM/GVO6apV0rLdtKx/ZU6oxnQ68vOQ2KwRADwWNXQc4fRrefRd69pSP6P/+CzNmQJ48\neNzxhf7v8DAiiN0f7KZJySaUKyfLQLu6vvz6JUrI3/M/MWvqygJQKNKGEoAswtQ0YbMRS0uI+Hc4\ni9stZt+1fTRe1pj/7t5lx2UnxOxf4fp1+OormWHVuDFUqSIXEzKQPaZbAHqyVHIIIe/Lvr5pO+eL\nFxAWlrIF8PTIOWjXTsbGenjA/PkybKhOHQDOBZ3jc5/6YPyMlc0PUL9YfSDOr6+HlqaGmZm0FI4c\nke+VACgUaUMJQDZhaSkraL5fvh+bemzi8t0rRPaux53wa7KEgr09TJok1wMWLpQB7yNGIAoX5lmX\n3nLxODL5vgPJER0dZwGkJgB+fvDJJ/D772k7b/xGLvEvlv/fnewxbk3f2dXknfm776Q/aNCg2OL+\nO3x3UH9JfQyEMSw5zDulqiU4d/yoopdRurTsDw/KBaRQpBUlANlE/HpA75V9j1/d9oH5AxhYi2WH\nDsUNNDPjcZcB/N7vNEPcTrPgeS/CN2yBli2JKFRUrjDv2wcREalez98/rk9vai6g/fvl9syZtH2P\nBAIQEAA//yxdV61b48o5lpacLK2ZCRNkFb0Y5pyaQ9vVbSlrU5b+4gTcd4n/cbrR1wFAWQAKRVpR\nApBNJK4HZPm0Diw8Ds9tmOjblPln5seO7dtXBs0cCa3OzQnzmD7mNh+Yb2BLcD3C5iyEpk0Rtrbg\n7g6LFiXbkFd3/zg6pm4B6AJw7lwaOpYJwYtLvgznN5pPbQhOTrK5bsGCsHIlozveYFL0Vwm6s4dH\nhTNixwiG7xhO6zKtOdzvMNGPCpM3r/T5vyq6AJibkyEhUShyE6oURDaRWABu3gQelKHIzuOEtXVn\nyLYhXLh9gSkNfmHXLlOGD5dLABIzHn/ZiXnzOlH512eUC9hDtxdbaL99B3nXrJFDnJykA71GDahR\ng+snywO2NG6ssXat9PUnboAeHS3Xm/Plk4vW3t4yRSGWiAi4ckX68E+ehP37cf3vP34Dnj0pJ11W\n7u6xd+Pqd2HF/+R6QpkyEBgSSNd1XTnqf5RPan/CtGbTMDQw5PHjpGsI6UUXgEKFVGN3hSKtKAHI\nJnQXkF4Qzt9fNiZvVt+S7au38eny8Uw/9jN/ex7nRZ61tGlTOsHxBQrIUtSffpqHvXvb8/337fng\nsODhUS8sz+6HQ4dkXOS6dQAMBbprVjw/UJY2LxwJH+qAaXEH+bhsYQEWFgTcEDS9F0n7VhEc3fmI\nyP/RRmgAAA8USURBVC+CweGedOH4+cmtvu5gZQXvvMPphp/SY0kLtu4sjYtLwu/YubOMgFq3Duq+\nfxD3De6EhIWwpvMauleMC4lKLooovegCoPz/CkXaUQKQTSRnATg5yXo6S5ca8nH5n3i3WAO6re4D\nQ6px23YuQrjH1sHXMTSEFi2kf//wYY1rpi5UG+4iE8pAdko5e5bZw7xwfOZNnXw+VOQyRqv3QEjC\nLC0nYBXATugORG/WwMZaFvapVk2WPq1YMa7ri6Zxei5cXZL8DdzREWrWCWOWx1d8uexnytiUYW+v\nvVSwq5BgXGYIgB52qvz/CkXaUQKQTaQmACDD5jt0aIvTjvPceced/tt7svXqeua0mUOhvEnvcsWK\nye316/JeHYutLbRowbdPWtChA1i+L6NK92+GRrWfS19PaCiEhvLRSAO8/IzYe8CQ1u9bEmpsyaF/\nDFP9HslGAcVw6c4lAlr15m70edzLDGVBl5+xMLFI9hyFkxb6TBd58sjvXbVqxs6jUOQm1CJwNpG4\nJ4De/LxKFflUf+aMDGv0OeXEOPtDTGs6jR2+Oyj/e3mWnV9GtEjYb7F4cbm9cSPpte7fly8XlzgX\nye3byBVTOzsoUYLIchX580x5SrYsC6VKUaa2DafPGb50IfjRIxmhamYWty80PJRxe8ZRbX41wkxu\nwaotVLrxR7I3fyBT1gBAiuaXX2b8PApFbkEJQDZhbi6Twx49kolUd+5ICyBPHrnweuYM/P23HNu6\npRFj643l/NDzlCtYjr6b+1JvcT1O3joZez4rKxk3n5wA6BFA5colbLgen3Pn4MkTaR2AtESePZML\nwamhu280DYQQbPTcSIU5FZh2dBp9qvTBe4Qntaza6ksRqZ4jo6jFX4UifSgByEYsLeXNLyBAvtfr\n3lSvLp9md++W+WCVY6ohlytYjn/6/8Pidou5/ug6tRbW4oONH+AT7IOmSTfQ9etJr6MngLm4yMVj\nM7OkAqCHfzaSJXhwc5Pbl+UD6DfvA/8doPai2nT+X2fymuTlcN/DLGy3EJs8NnTtKgVGLwtx4oQs\nShcVJaOR4reDVCgUWYcSgGzE0lK6gPTin05OcuvmJtduN2+WfYbjP9kaaAb0q9oPn498GF9vPBs9\nN+LyuwvuG9yxdrmUogVgbi4FQtOkFZA4GWz/fqhQIa6VorOzDA46fTrl+UeLaHy0rQS1aETj5Y0J\nDAlkUbtFnB96PrakA0CXLnK7YoUsR123rtwuWyaXH6KiMscCUCgU6SNDAqBpWldN065omhataZpb\nKuNaaprmrWman6Zp4zNyzZyElZV8gvb3l+/jWwAgS0W0aJH8sflM8zG16VSuf3ydMXXGsNV7K0cq\nVuaSWwNWXFzB84jnsWM9PeUNXe9Z7OCQ0AIID5eF1HT3D8h1CFfX5C2A209vM+v4LFx+d+FcuXaE\n5/Xjl+a/4DvCl/5V+2NkkDC2oFgxGTj0zTfyyb9/f6hdWyYH699dCYBCkfVk1AK4DHQCDqc0QNM0\nQ+B3oBVQHnDXNK18SuNzE7oLSLcA9KYq+kIwQLNmqZ/DzsKOH5v9yI2Pb9Da+EeizIPo9VcvHKY7\n4L7BndWXVnPl6qMEMfqJLYBLl6S//513Ep67enXpuomMFFx7eI35Z+bT/M/mFPmlCB/v/pgCpgUo\nfHQ1ba9eY3Sd0ZgZmZESI0dKF9TOnbBgAcycKefwxRfyc+UCUiiyngyFgQohPIEksemJqAn4CSGu\nxYxdA7QHPDJy7ZyApaXMr/L3l9Ga5uZyv7k5VKokn9jt7NJ2Lps8NvQp/Rk7Joxl4b6DHA1ZwTbf\nbay5vAbcDdhvUIFBW2rhVtiNSKdSBFxw4nmEI2ZGZpw7J//9qrhGEfzsEfef3cf3gS+3S3nwrMVl\nis04TOAz6VsqaVWSL975AvdK7pS3LY/DRLBu9/L59ewpXzq1asH778uq1/rvQqFQZC1ZkQdQBPCP\n9z4ASEOR35yP7gLScwDis2pVnBWQVmQugIZdaCMWtW9EtIhm+b4T9JuyC4c2J9notZGF5xaCFdAb\n8nwPGhoGwgS+MKLc6mR6RZYojAO1+KLVWBqXaEy5guUSCH5GInimToWNG2VJaSUACkXW81IB0DRt\nL5BcfuUEIcTmzJ6QpmmDgcEATonvijmM+C4gZ+eEnyUuq5AWEucCGGgGaP9v7/5D67rLOI6/P00y\nF7ZKzWxNm5s2c9SuUqSOUFZWdGKdY4zVicKcICJSJg4nTK3Y4aajA9kUQfaH1Q0VqjKYxYGVdWMb\nTtboutG5H+0kOLu1dsbpqi1SarvHP773mOvNvcm5uXc5ObmfF1xy783pPc8h6Xny/fV8j26Exzay\n625YuzY4/M/D3L3rMHf94DBfvv0I555/int+dBr1/IfPfmoxA/0DDPQPcNHbLuJdA2sZXrqE938O\nPr9h6vlOnWrv5r1yJdx8M+zYMTn4bGZzZ8YEEBGb2zzHUaB2Y79K9b1m59sJ7AQYHR1tfxuseWzJ\nklRaZ3w87R3crmXL0hTP2plAY2Op3M/FF6euupElI1w+MsJdz8DH3pH6+b99ddqB8rbLp37m8PDk\nQG29bL/fdv56v+22tOlZtpLZzObOXEwDfRJYLelCSecA1wEPzMF5572sINzp01O7gGZDSp9TuxZg\n3740A2dRzU+6djHY+HgaAG5WQqFSmVynUG+6MhB59fbm2/XLzDqv3Wmg10o6AmwEfiXpwer7KyTt\nAYiIM8CNwIPAQeC+iHi+vbAXhtobZ57Nz/MYGZlsAZw4kWb4VHdf/J+sHMSxY2mWD0yfAI42aa91\nIgGYWXHanQW0G9jd4P2/AFfVvN4D7GnnXAtR7Y2zU8Mdq1bBgQPp+f79qcZ/fQJYtiy1Fl59Ne0d\n09dXV/e/xtBQqkl09uzUQWknALNy80rgAmVdQNC5FsCqVTAxkbp19u1L79V3sfT2pmmnWQtg3bpU\n0K2RSiWNU0xMTP2eE4BZuTkBFCi7cfb2dq6OfTYT6OWXUwJYswYGBqYeNzg4mQCmK6GcLU5rNA7g\nBGBWbk4ABcpunJVK63P+m6ndF2BsbGr3T2b58lTm4bXXpk8AQ0Ppa6NxACcAs3JzAihQVv6gU90/\nMJkAHnkk3dybJYDBwdS3D+21AOr3AjCz8nACKFBfX6rh38n1bitWpC6lbG/4Sy9tfFw2E0hKtYea\nWbo0xdksAWR7AZhZ+XhLyILdckuap98pPT2pRfHSS7B4cSrx3Eg25rB6dUpCzSxalLqBmnUBufvH\nrLycAAq2bVvnP3NkJCWADRuajy1kLYA8e+gODU3fAjCzcnIX0AKUjQM06/+HyQSwfv3Mn9dsNfDx\n4y7jbFZmTgALUJYAmvX/Qyo3vXEjXJOjlHOWAKKuMpNbAGbl5i6gBWjTptQNdNllzY9ZsgSeeCLf\n51Uqqern66///5oCJwCzcnMLYAHavDmNAXTq5pytBajvBnICMCs3JwCbUaO1AO3uBWBmxXMCsBk1\nSgCd2AvAzIrlBGAzGhxMi71q1wK4DIRZ+TkB2Iz6+lISqG0BOAGYlZ8TgOVSvxbACcCs/JwALBcn\nALOFxwnAcqmvB+QEYFZ+TgCWS6WSZv6cOJFeOwGYlZ8TgOWSTQXNWgHHj6fB4f7+4mIys/Y4AVgu\n9auBvReAWfk5AVgujVoA7v4xKzcnAMulWQvAzMrLCcBy6e+HCy6AO+9Mu4g99pj3AjArO5eDttzu\nuAMefxzOnoVLLoHrry86IjNrhxOA5bZ1a3qY2cLgLiAzsy7VVgKQ9HFJz0t6Q9LoNMf9WdKzkg5I\n2t/OOc3MrDPa7QJ6Dvgo8P0cx34gIl5r83xmZtYhbSWAiDgIIK8GMjMrnbkaAwhgr6SnJHkY0cxs\nHpixBSDpYWCwwbe2R8Qvc55nU0QclbQMeEjSoYj4TZPzbQW2AqxcuTLnx5uZWatmTAARsbndk0TE\n0erXCUm7gQ1AwwQQETuBnQCjo6PR7rnNzKyxN70LSNJ5khZnz4ErSIPHZmZWIEXM/o9sSdcC3wOW\nAseBAxHxYUkrgB9GxFWS3gnsrv6TXuCnEbEj5+f/DTg86wCbeztQ5hlJZY8fyn8Njr94Zb+GNyv+\nVRGxNM+BbSWAspK0PyKarluY78oeP5T/Ghx/8cp+DfMhfq8ENjPrUk4AZmZdqlsTwM6iA2hT2eOH\n8l+D4y9e2a+h8Pi7cgzAzMy6twVgZtb1ujIBSLpd0h+q1Un3VqetloqkOyUdql7Hbkml2qAxbyXZ\n+UbSlZJelDQu6atFx9MqSfdKmpBUyrU4koYlPSrphervz01Fx9QqSedK+r2kZ6rX8I3CYunGLiBJ\nb42If1WffwF4d0TcUHBYLZF0BfBIRJyR9C2AiNhWcFi5SVoLvEGqJPuliJj3ZcIl9QB/BD4EHAGe\nBD4RES8UGlgLJL0POAn8JCLWFR1PqyQtB5ZHxNPVBaZPAR8p2c9AwHkRcVJSH/Bb4KaIGJvrWLqy\nBZDd/KvOIxWrK5WI2BsRZ6ovx4BKkfG0KiIORsSLRcfRog3AeET8KSJOAz8HthQcU0uqNbj+UXQc\nsxURxyLi6erzE8BBYKjYqFoTycnqy77qo5B7UFcmAABJOyS9AnwS+HrR8bTpM8Cviw6iCwwBr9S8\nPkLJbj4LiaQR4L3A74qNpHWSeiQdACaAhyKikGtYsAlA0sOSnmvw2AIQEdsjYhjYBdxYbLSNzXQN\n1WO2A2dI1zGv5InfbDYknQ/cD3yxrkVfChFxNiLWk1ruGyQV0h23YDeFb6GK6S5gD3DrmxjOrMx0\nDZI+DVwNfDDm4WBOJyrJzjNHgeGa15XqezaHqv3m9wO7IuIXRcfTjog4LulR4EoKKJK5YFsA05G0\nuublFuBQUbHMlqQrga8A10TEv4uOp0s8CayWdKGkc4DrgAcKjqmrVAdQ7wEORsR3io5nNiQtzWbt\nSeonTSoo5B7UrbOA7gfWkGahHAZuyPYsKAtJ48BbgL9X3xor00ymZpVki41qZpKuAr4L9AD35q1s\nO19I+hlwOakS5V+BWyPinkKDaoGkTcDjwLOk/78AX4uIPcVF1RpJ7wF+TPodWgTcFxHfLCSWbkwA\nZmbWpV1AZmbmBGBm1rWcAMzMupQTgJlZl3ICMDPrUk4AZmZdygnAzKxLOQGYmXWp/wLodM164yGa\nGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86bdab14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(x_train, y_train, minibatch_size):\n",
    "    \n",
    "    x = tf.get_default_graph().get_tensor_by_name('x:0')\n",
    "    y = tf.get_default_graph().get_tensor_by_name('y:0')\n",
    "        \n",
    "    forward_pass = compute_forward_pass()\n",
    "\n",
    "    mse = tf.square(tf.sub(tf.get_default_graph().get_tensor_by_name('y:0'), forward_pass))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.add(mse, 0.001 * compute_l2_regularization()))\n",
    "\n",
    "    train_op = tf.train.AdagradOptimizer(0.8).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph=tf.get_default_graph()) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        n_minibatch = np.int(np.ceil(x_train.shape[0]/np.float(minibatch_size)))\n",
    "        print('Nr of minibatches: %d' % n_minibatch)\n",
    "    \n",
    "        for epoch_ix in range(3000):\n",
    "            epoch_loss = 0\n",
    "            for minibatch_ix in range(n_minibatch):\n",
    "                _, output_loss = session.run([train_op, loss], feed_dict={x: np.matrix(x_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]).T, y: y_train[minibatch_ix*minibatch_size:(minibatch_ix+1)*minibatch_size]})\n",
    "                epoch_loss += output_loss\n",
    "\n",
    "            if (epoch_ix%300) == 0:\n",
    "                print(epoch_loss, compute_l2_regularization().eval())\n",
    "        \n",
    "        w1, b1, w2 = get_variables(reuse=True)\n",
    "        \n",
    "        print(w1.eval())\n",
    "        print(b1.eval())\n",
    "        print(w2.eval())\n",
    "        \n",
    "        saver.save(session, \"/tmp/model.ckpt\")\n",
    "        print('Session saved')\n",
    "\n",
    "    return saver\n",
    "\n",
    "def predict(x_test, saver):\n",
    "    x = tf.get_default_graph().get_tensor_by_name('x:0')\n",
    "    \n",
    "    predictions = None\n",
    "    \n",
    "    with tf.Session(graph=tf.get_default_graph()) as session:\n",
    "        \n",
    "#         i dont run the initializer but the session.restore\n",
    "        saver.restore(session, \"/tmp/model.ckpt\")\n",
    "        print(\"Session restored\")\n",
    "        \n",
    "        predictions = session.run(compute_forward_pass(), feed_dict={x: np.matrix(x_test).T})\n",
    "        \n",
    "        assert predictions is not None\n",
    "        \n",
    "        w1, b1, w2 = get_variables(reuse=True)\n",
    "        \n",
    "#         now these variables are the same as when training ended!\n",
    "        print(w1.eval())\n",
    "        print(b1.eval())\n",
    "        print(w2.eval())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "graph_1 = create_graph()\n",
    "\n",
    "with graph_1.as_default():\n",
    "    saver = train(x_train, y_train, minibatch_size)\n",
    "    predictions = predict(x_train, saver)\n",
    "\n",
    "plt.plot(x_train, y_train, color='blue')\n",
    "plt.plot(x_train, y_sin, color='green')\n",
    "plt.plot(x_train, np.array(predictions).reshape((-1,)), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### A comment on graphs handling\n",
    "Operations and Tensors are associated to a specific graph. For any computation, the intervening variables must be part of the same graph.\n",
    "\n",
    "There is a default graph, which is instantiated when the library is imported. Additionally we can create graphs at will by calling `tf.Graph()`. If we create a new graph, it is not assigned as the default graph.\n",
    "\n",
    "Using the statement `with [graph].as_default()`, we are specifying that the operations within the block are gonna use [graph] as default.\n",
    "\n",
    "We can retrieve the default graph via `tf.get_default_graph()`.\n",
    "\n",
    "When calling `tf.reset_default_graph()`, a new graph is created and assigned as default.\n",
    "\n",
    "Finally, we can query existing tensors in a graph using `print([n.name for n in tf.get_default_graph().as_graph_def().node])`.\n",
    "\n",
    "See the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f86bdb38f98>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f86bd3f0898>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f86bdb38e48>\n",
      "True <tensorflow.python.framework.ops.Graph object at 0x7f86bdb38f98>\n"
     ]
    }
   ],
   "source": [
    "# i create a new graph\n",
    "my_graph = tf.Graph()\n",
    "print(my_graph)\n",
    "\n",
    "# the new graph is not automatically assigned as the default graph.\n",
    "print(tf.get_default_graph())\n",
    "\n",
    "# reseting the graph creates a new default graph.\n",
    "tf.reset_default_graph()\n",
    "print(tf.get_default_graph())\n",
    "\n",
    "# when using `[graph].as_default()` we set [graph] as default for that scope\n",
    "with my_graph.as_default():\n",
    "    print(my_graph==tf.get_default_graph(), tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Saving and restoring graphs (and their states)\n",
    "What we have seen so far was: with an existing graph instance (always the same instance!), creating and closing sessions and saving and retrieving their states. This section deals with the case when we want to use a trained model but we no longer have the corresponding graph instance. In the documentation, this is referred to as \"Exporting and Importing a MetaGraph\".\n",
    "\n",
    "A Tensorflow model consists of two main things, which are saved/restored separatedly -also, manually-:\n",
    "1. _the graph definition: saved and loaded using_ `tf.train.export_meta_graph()` and `tf.train.import_meta_graph()`.\n",
    "2. _the graph's state (the variables' values)_: saved and restored using `tf.train.Saver().save()` and `tf.train.Saver().restore()`, respectively.\n",
    "\n",
    "The workflow for saving and restoring models should be:\n",
    "1. Instantiate collections and append the the graph objects (placeholders, variables, ops) we will later retrieve `tf.add_to_collection('vars', w1)`.\n",
    "2. Instantiate a Saver `saver = tf.train.Saver()`.\n",
    "3. Save the session `saver.save(session, '/tmp/model.ckpt')` (by default, this statement will export the MetaGraph).\n",
    "4. Export the MetaGraph `tf.train.export_meta_graph(filename='/tmp/model.meta')` (if not performed in the previous op).\n",
    "5. Import the MetaGraph `saver = tf.train.import_meta_graph('/tmp/model.meta')` (this will create a Saver object).\n",
    "6. Restore the session `saver.restore(session, '/tmp/model.ckpt')`.\n",
    "7. Retrieve the graph objects (placeholders, variables, ops) from the collection `tf.get_collection('vars')`.\n",
    "\n",
    "_\"The MetaGraph contains the information required to continue training, perform evaluation, or run inference on a previously trained graph.\"_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph_1 is:  <tensorflow.python.framework.ops.Graph object at 0x7f86bc3a5fd0>\n",
      "The default graph is graph_1: True <tensorflow.python.framework.ops.Graph object at 0x7f86bc3a5fd0>\n",
      "The value of graph_1 w is:  [[ 0.10279728]]\n",
      "Session saved\n",
      "MetaGraph exported\n",
      "Graph_2 is:  <tensorflow.python.framework.ops.Graph object at 0x7f86bdbbc2b0>\n",
      "The default graph is graph_2: True <tensorflow.python.framework.ops.Graph object at 0x7f86bdbbc2b0>\n",
      "The default graph is graph_2: True <tensorflow.python.framework.ops.Graph object at 0x7f86bdbbc2b0>\n",
      "[[ 0.10279728]]\n"
     ]
    }
   ],
   "source": [
    "graph_1 = tf.Graph()\n",
    "print('Graph_1 is: ', graph_1)\n",
    "\n",
    "with graph_1.as_default():\n",
    "    \n",
    "    x = tf.placeholder(dtype=tf.int64, name='x')\n",
    "    \n",
    "    w1 = tf.Variable(initial_value=tf.random_normal([1,1], stddev=0.2), name='w1')\n",
    "    w2 = tf.Variable(initial_value=tf.random_normal([1,1], stddev=0.2), name='w2')\n",
    "    \n",
    "#     create collections and add objects to them\n",
    "    tf.add_to_collection('place', x)\n",
    "    tf.add_to_collection('params', w1)\n",
    "    tf.add_to_collection('params', w2)\n",
    "\n",
    "#     instantiate a saver\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph_1) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print('The default graph is graph_1: %s %s' % (tf.get_default_graph()==graph_1, tf.get_default_graph()))\n",
    "\n",
    "    print('The value of graph_1 w is: ', w1.eval())\n",
    "    \n",
    "#     save the session\n",
    "    saver.save(session, '/tmp/model.ckpt')\n",
    "    print('Session saved')\n",
    "\n",
    "#     save the MetaGraph (this is already done by the previous statement)\n",
    "    tf.train.export_meta_graph(filename='/tmp/model.meta')\n",
    "    print('MetaGraph exported')\n",
    "    \n",
    "\n",
    "graph_2 = tf.Graph()\n",
    "print('Graph_2 is: ', graph_2)\n",
    "\n",
    "with tf.Session(graph=graph_2) as session:\n",
    "    print('The default graph is graph_2: %s %s' % (tf.get_default_graph()==graph_2, tf.get_default_graph()))\n",
    "    \n",
    "#     i restore the MetaGraph (this creates a new saver, i no longer need the previous one!)\n",
    "    saver = tf.train.import_meta_graph('/tmp/model.meta')\n",
    "#     i restore the session\n",
    "    saver.restore(session, '/tmp/model.ckpt')\n",
    "    \n",
    "#     note that the default graph continues to be graph_2, not graph_1!\n",
    "    print('The default graph is graph_2: %s %s' % (tf.get_default_graph()==graph_2, tf.get_default_graph()))\n",
    "\n",
    "    w1, w2 = tf.get_collection('params')\n",
    "    \n",
    "    print(w1.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Also\n",
    "Learning visualizations: https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "        \n",
    "Embedding visualisations: https://www.tensorflow.org/get_started/embedding_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Seeding\n",
    "Operations that run random statements can be seeded either at: (1) operation level; or (2) graph level.\n",
    "\n",
    "I guess it is more practical to seed at graph-level. This is done by calling `tf.set_random_seed(value)`.\n",
    "\n",
    "*Note* that this must be done for each graph! And if no graph is specified, as always, it will impact the default graph. See below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The wrong way (common mistake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05492095]]\n",
      "[[ 0.03341978]]\n"
     ]
    }
   ],
   "source": [
    "# instantiate a graph\n",
    "graph_1 = tf.Graph()\n",
    "\n",
    "# this way im seeding the default graph\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "with graph_1.as_default():\n",
    "#     define a random var\n",
    "    x = tf.random_normal([1,1], stddev=0.2)\n",
    "\n",
    "with tf.Session(graph=graph_1) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(x.eval())\n",
    "\n",
    "with tf.Session(graph=graph_1) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(x.eval())\n",
    "    \n",
    "# Result: there is no seed for graph_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate a graph\n",
    "graph_1 = tf.Graph()\n",
    "\n",
    "# this way im seeding the  graph\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "with graph_1.as_default():\n",
    "#     define a random var\n",
    "    x = tf.random_normal([1,1], stddev=0.2)\n",
    "\n",
    "with tf.Session(graph=graph_1) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(x.eval())\n",
    "\n",
    "with tf.Session(graph=graph_1) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(x.eval())\n",
    "    \n",
    "# Result: there is no seed for graph_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
